{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2vec transformation of our TMDB and IMDB movie plots\n",
    "\n",
    "This notebook applies a word2vec transformation to our TMDB and IMDB movie plots. Further design considerations and analysis are below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "from ast import literal_eval\n",
    "from gensim import models\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from stop_words import get_stop_words\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tmdb_id</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>tmdb_genres</th>\n",
       "      <th>imdb_genres</th>\n",
       "      <th>binary_tmdb</th>\n",
       "      <th>binary_imdb</th>\n",
       "      <th>tmdb_plot</th>\n",
       "      <th>imdb_plot</th>\n",
       "      <th>popularity</th>\n",
       "      <th>release_date</th>\n",
       "      <th>title</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "      <th>tmdb_clean_plot</th>\n",
       "      <th>imdb_clean_plot</th>\n",
       "      <th>tmdb_w2v_plot</th>\n",
       "      <th>imdb_w2v_plot</th>\n",
       "      <th>tmdb_bow_plot</th>\n",
       "      <th>imdb_bow_plot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>278</td>\n",
       "      <td>tt0111161</td>\n",
       "      <td>[18, 80]</td>\n",
       "      <td>[80, 18]</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...</td>\n",
       "      <td>Framed in the 1940s for the double murder of h...</td>\n",
       "      <td>Chronicles the experiences of a formerly succe...</td>\n",
       "      <td>28.527767</td>\n",
       "      <td>1994-09-23</td>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>8.5</td>\n",
       "      <td>9773</td>\n",
       "      <td>['framed', '1940s', 'double', 'murder', 'wife'...</td>\n",
       "      <td>['chronicles', 'experiences', 'formerly', 'suc...</td>\n",
       "      <td>[0.014165705069899559, 0.035729147493839264, 0...</td>\n",
       "      <td>[0.004663567990064621, 0.09018586575984955, -0...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>238</td>\n",
       "      <td>tt0068646</td>\n",
       "      <td>[18, 80]</td>\n",
       "      <td>[80, 18]</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...</td>\n",
       "      <td>Spanning the years 1945 to 1955, a chronicle o...</td>\n",
       "      <td>When the aging head of a famous crime family d...</td>\n",
       "      <td>36.965452</td>\n",
       "      <td>1972-03-14</td>\n",
       "      <td>The Godfather</td>\n",
       "      <td>8.5</td>\n",
       "      <td>7394</td>\n",
       "      <td>['spanning', 'years', '1945', '1955', 'chronic...</td>\n",
       "      <td>['aging', 'head', 'famous', 'crime', 'family',...</td>\n",
       "      <td>[-0.016820836812257767, 0.05966977775096893, -...</td>\n",
       "      <td>[-0.013326308690011501, 0.08134819567203522, 0...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>424</td>\n",
       "      <td>tt0108052</td>\n",
       "      <td>[18, 36, 10752]</td>\n",
       "      <td>[18, 36]</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>The true story of how businessman Oskar Schind...</td>\n",
       "      <td>Oskar Schindler is a vainglorious and greedy G...</td>\n",
       "      <td>19.945455</td>\n",
       "      <td>1993-11-29</td>\n",
       "      <td>Schindler's List</td>\n",
       "      <td>8.4</td>\n",
       "      <td>5518</td>\n",
       "      <td>['true', 'story', 'businessman', 'oskar', 'sch...</td>\n",
       "      <td>['oskar', 'schindler', 'vainglorious', 'greedy...</td>\n",
       "      <td>[0.0758906751871109, 0.02254812978208065, 0.06...</td>\n",
       "      <td>[0.05338115245103836, 0.10281133651733398, 0.0...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>240</td>\n",
       "      <td>tt0071562</td>\n",
       "      <td>[18, 80]</td>\n",
       "      <td>[80, 18]</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...</td>\n",
       "      <td>In the continuing saga of the Corleone crime f...</td>\n",
       "      <td>The continuing saga of the Corleone crime fami...</td>\n",
       "      <td>30.191804</td>\n",
       "      <td>1974-12-20</td>\n",
       "      <td>The Godfather: Part II</td>\n",
       "      <td>8.4</td>\n",
       "      <td>4249</td>\n",
       "      <td>['continuing', 'saga', 'corleone', 'crime', 'f...</td>\n",
       "      <td>['continuing', 'saga', 'corleone', 'crime', 'f...</td>\n",
       "      <td>[-0.05790800228714943, 0.07111673057079315, -0...</td>\n",
       "      <td>[-0.05151921883225441, 0.07896284759044647, -0...</td>\n",
       "      <td>[0.0, 0.0, 0.34648671489524274, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.324...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>452522</td>\n",
       "      <td>tt0278784</td>\n",
       "      <td>[18, 9648]</td>\n",
       "      <td>[80, 18, 9648, 53]</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, ...</td>\n",
       "      <td>Standalone version of the series pilot with an...</td>\n",
       "      <td>When beautiful, young Laura Palmer is found br...</td>\n",
       "      <td>5.969249</td>\n",
       "      <td>1989-12-31</td>\n",
       "      <td>Twin Peaks</td>\n",
       "      <td>8.4</td>\n",
       "      <td>123</td>\n",
       "      <td>['standalone', 'version', 'series', 'pilot', '...</td>\n",
       "      <td>['beautiful', 'young', 'laura', 'palmer', 'fou...</td>\n",
       "      <td>[-0.05888228118419647, -0.05345569923520088, -...</td>\n",
       "      <td>[0.0026558770332485437, 0.10140948742628098, 0...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tmdb_id    imdb_id      tmdb_genres         imdb_genres  \\\n",
       "0      278  tt0111161         [18, 80]            [80, 18]   \n",
       "1      238  tt0068646         [18, 80]            [80, 18]   \n",
       "2      424  tt0108052  [18, 36, 10752]            [18, 36]   \n",
       "3      240  tt0071562         [18, 80]            [80, 18]   \n",
       "4   452522  tt0278784       [18, 9648]  [80, 18, 9648, 53]   \n",
       "\n",
       "                                         binary_tmdb  \\\n",
       "0  [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...   \n",
       "1  [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...   \n",
       "2  [0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3  [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...   \n",
       "4  [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...   \n",
       "\n",
       "                                         binary_imdb  \\\n",
       "0  [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...   \n",
       "1  [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...   \n",
       "2  [0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3  [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...   \n",
       "4  [0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, ...   \n",
       "\n",
       "                                           tmdb_plot  \\\n",
       "0  Framed in the 1940s for the double murder of h...   \n",
       "1  Spanning the years 1945 to 1955, a chronicle o...   \n",
       "2  The true story of how businessman Oskar Schind...   \n",
       "3  In the continuing saga of the Corleone crime f...   \n",
       "4  Standalone version of the series pilot with an...   \n",
       "\n",
       "                                           imdb_plot  popularity release_date  \\\n",
       "0  Chronicles the experiences of a formerly succe...   28.527767   1994-09-23   \n",
       "1  When the aging head of a famous crime family d...   36.965452   1972-03-14   \n",
       "2  Oskar Schindler is a vainglorious and greedy G...   19.945455   1993-11-29   \n",
       "3  The continuing saga of the Corleone crime fami...   30.191804   1974-12-20   \n",
       "4  When beautiful, young Laura Palmer is found br...    5.969249   1989-12-31   \n",
       "\n",
       "                      title  vote_average  vote_count  \\\n",
       "0  The Shawshank Redemption           8.5        9773   \n",
       "1             The Godfather           8.5        7394   \n",
       "2          Schindler's List           8.4        5518   \n",
       "3    The Godfather: Part II           8.4        4249   \n",
       "4                Twin Peaks           8.4         123   \n",
       "\n",
       "                                     tmdb_clean_plot  \\\n",
       "0  ['framed', '1940s', 'double', 'murder', 'wife'...   \n",
       "1  ['spanning', 'years', '1945', '1955', 'chronic...   \n",
       "2  ['true', 'story', 'businessman', 'oskar', 'sch...   \n",
       "3  ['continuing', 'saga', 'corleone', 'crime', 'f...   \n",
       "4  ['standalone', 'version', 'series', 'pilot', '...   \n",
       "\n",
       "                                     imdb_clean_plot  \\\n",
       "0  ['chronicles', 'experiences', 'formerly', 'suc...   \n",
       "1  ['aging', 'head', 'famous', 'crime', 'family',...   \n",
       "2  ['oskar', 'schindler', 'vainglorious', 'greedy...   \n",
       "3  ['continuing', 'saga', 'corleone', 'crime', 'f...   \n",
       "4  ['beautiful', 'young', 'laura', 'palmer', 'fou...   \n",
       "\n",
       "                                       tmdb_w2v_plot  \\\n",
       "0  [0.014165705069899559, 0.035729147493839264, 0...   \n",
       "1  [-0.016820836812257767, 0.05966977775096893, -...   \n",
       "2  [0.0758906751871109, 0.02254812978208065, 0.06...   \n",
       "3  [-0.05790800228714943, 0.07111673057079315, -0...   \n",
       "4  [-0.05888228118419647, -0.05345569923520088, -...   \n",
       "\n",
       "                                       imdb_w2v_plot  \\\n",
       "0  [0.004663567990064621, 0.09018586575984955, -0...   \n",
       "1  [-0.013326308690011501, 0.08134819567203522, 0...   \n",
       "2  [0.05338115245103836, 0.10281133651733398, 0.0...   \n",
       "3  [-0.05151921883225441, 0.07896284759044647, -0...   \n",
       "4  [0.0026558770332485437, 0.10140948742628098, 0...   \n",
       "\n",
       "                                       tmdb_bow_plot  \\\n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3  [0.0, 0.0, 0.34648671489524274, 0.0, 0.0, 0.0,...   \n",
       "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                       imdb_bow_plot  \n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.324...  \n",
       "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read in dataset\n",
    "movies = pd.read_csv('Data/movies.csv', encoding='utf8', \n",
    "                     converters={'tmdb_genres':literal_eval, 'imdb_genres':literal_eval})\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Clean plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "174"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define tokenizer\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "#set stop words list\n",
    "english_stop = get_stop_words('en')\n",
    "len(english_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#function to clean plots\n",
    "def clean_plot(plot):\n",
    "    plot = plot.lower()\n",
    "    plot = tokenizer.tokenize(plot)\n",
    "    plot = [word for word in plot if word not in english_stop]\n",
    "    return plot\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Framed in the 1940s for the double murder of his wife and her lover, upstanding banker Andy Dufresne begins a new life at the Shawshank prison, where he puts his accounting skills to work for an amoral warden. During his long stretch in prison, Dufresne comes to be admired by the other inmates -- including an older prisoner named Red -- for his integrity and unquenchable sense of hope\n",
      "['framed', '1940s', 'double', 'murder', 'wife', 'lover', 'upstanding', 'banker', 'andy', 'dufresne', 'begins', 'new', 'life', 'shawshank', 'prison', 'puts', 'accounting', 'skills', 'work', 'amoral', 'warden', 'long', 'stretch', 'prison', 'dufresne', 'comes', 'admired', 'inmates', 'including', 'older', 'prisoner', 'named', 'red', 'integrity', 'unquenchable', 'sense', 'hope']\n"
     ]
    }
   ],
   "source": [
    "#check first movie's clean plot\n",
    "print(movies.tmdb_plot[0])\n",
    "print(clean_plot(movies.tmdb_plot[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#apply to movies df for both imdb and tmdb\n",
    "movies['tmdb_clean_plot'] = movies['tmdb_plot'].apply(lambda x: clean_plot(x))\n",
    "movies['imdb_clean_plot'] = movies['imdb_plot'].apply(lambda x: clean_plot(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    [spanning, years, 1945, 1955, chronicle, ficti...\n",
       "2    [true, story, businessman, oskar, schindler, s...\n",
       "3    [continuing, saga, corleone, crime, family, yo...\n",
       "4    [standalone, version, series, pilot, alternate...\n",
       "Name: tmdb_clean_plot, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check some outputs\n",
    "movies.tmdb_clean_plot[1:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Apply word2vec Transformation of Plots\n",
    "\n",
    "For this transformation we will use the Google News pretrained word2vec model that was trained on a more than 3 billion word corpus. It contains 3 million words, each represented by a 300-dimension vector. We make a couple of design choices for how we transform our movie plots:\n",
    "\n",
    "- If a word in the cleaned plots (lowered, punctuation and stop word dropped, tokenized) is in the word2vec model, add it to a running list for that plot.\n",
    "- If a word is not in the word2vec model, skip it. We print some of these words below for example.\n",
    "- After collecting all the word vectors for a particular plot, take the column-wise mean and store the plot as a 300-dimension average vector of its words.\n",
    "\n",
    "The assumption we make by taking the mean of each plot is that the resulting 300-dimension vector will point in the direction of one or more genres. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load the pretrained google news word2vec model\n",
    "model = models.KeyedVectors.load_word2vec_format('data/GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#collect words not in the Google News w2v model\n",
    "not_w2v = []\n",
    "\n",
    "#word2vec function\n",
    "def apply_words2Vec(cleaned_plot):\n",
    "    \n",
    "    \"\"\"\n",
    "    apply_words2Vec()\n",
    "    -applies the following transformations to the cleaned plot of a movie:\n",
    "        1) removes words that are not in google's model\n",
    "        2) creates a vector representation of each word\n",
    "        3) converts the resulting nd_array into a 1d_array via np.mean()\n",
    "    -also keeps track of all words not found in google's model\n",
    "    \n",
    "    -inputs: cleaned_plot (string)\n",
    "    \n",
    "    -outputs: vector representation of plot\n",
    "    \n",
    "    \"\"\"\n",
    "    vecs=[]\n",
    "    for word in cleaned_plot:\n",
    "        #add word vector to list if it is in the google model\n",
    "        try:\n",
    "            vecs.append(model.word_vec(word)) \n",
    "        except:\n",
    "            #if the word is not in the w2v model, add it to\n",
    "            #our list of skipped words\n",
    "            not_w2v.append(word)\n",
    "    \n",
    "\n",
    "    \n",
    "    vecs = np.mean(vecs, axis=0)\n",
    "    return vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#apply transformation to both sets of plots and add columns to df\n",
    "movies['tmdb_w2v_plot'] = movies['tmdb_clean_plot'].apply(lambda x: apply_words2Vec(x))\n",
    "movies['imdb_w2v_plot'] = movies['imdb_clean_plot'].apply(lambda x: apply_words2Vec(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((300,), (300,))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check shapes of first movie vectors to confirm 300-dimensions\n",
    "movies.loc[0,'tmdb_w2v_plot'].shape, movies.loc[0,'imdb_w2v_plot'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each TMDB and IMDB plot has been transformed into a 300-dimension representation of that plot. We will use these features as predictors in our multi-lable classification modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5416\n",
      "['valerie' 'addie' 'arroway' '1988' 'waititi' 'rocco' 'matlock' '1920s'\n",
      " 'needham' 'gertrude' 'lili' 'rapunzel' '500' 'josey' '1996' 'sicily'\n",
      " '26th' 'jessup' 'marston' 'napaloni' 'dealan' 'katarina' 'isabelle'\n",
      " 'urskeks' 'pistone' 'napua' 'sheryl' 'saroo' 'trinh' 'millman'\n",
      " 'burpelson' '1942' 'discreteness' 'verona' 'lucile' 'cecelia' 'lestat'\n",
      " 'maisie' 'onllwyn' 'cranley' '1999' 'kyla' 'renton' '1964' '1984'\n",
      " 'moonscar' 'kristoff' 'trask' 'kirkeby' 'malone']\n"
     ]
    }
   ],
   "source": [
    "#print some of our skipped words\n",
    "print(len(not_w2v))\n",
    "np.random.seed(1212)\n",
    "print(np.random.choice(not_w2v, 50, replace=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 5416 words in our cleaned TMDB and IMDB plots that were skipped when applying the word2vec transformation. As seen above, the random sample of 50 of those words are mostly years, numbers, and proper nouns. This is not surprising, and we suspect will not have a large impact on the resulting word2vec representations of our movie plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All TMDB movies have a word2vec representation.\n",
      "All IMDB movies have a word2vec representation.\n"
     ]
    }
   ],
   "source": [
    "#check that each plot has a corresponding word2vec representation\n",
    "for plot in movies.tmdb_w2v_plot:\n",
    "    if len(plot) != 300:\n",
    "        print(\"AH! no word2vec representation\")\n",
    "print('All TMDB movies have a word2vec representation.')\n",
    "\n",
    "for plot in movies.imdb_w2v_plot:\n",
    "    if len(plot) != 300:\n",
    "        print(\"AH! no word2vec representation\")\n",
    "print('All IMDB movies have a word2vec representation.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Update and save DataFrame for modeling and analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#convert to lists for csv writing and reading ease\n",
    "movies['tmdb_w2v_plot'] = movies['tmdb_w2v_plot'].apply(lambda x: x.tolist())\n",
    "movies['imdb_w2v_plot'] = movies['imdb_w2v_plot'].apply(lambda x: x.tolist())\n",
    "\n",
    "movies.to_csv('data/movies.csv', encoding=\"utf-8\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We have now transformed and saved each plot as a 300-dimension word2vec representation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
