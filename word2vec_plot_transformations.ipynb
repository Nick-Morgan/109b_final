{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2vec transformation of our TMDB and IMDB movie plots\n",
    "\n",
    "This notebook applies a word2vec transformation to our TMDB and IMDB movie plots. Further design considerations and analysis are below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "from ast import literal_eval\n",
    "from gensim import models\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from stop_words import get_stop_words\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tmdb_id</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>tmdb_genres</th>\n",
       "      <th>imdb_genres</th>\n",
       "      <th>binary_tmdb</th>\n",
       "      <th>binary_imdb</th>\n",
       "      <th>tmdb_plot</th>\n",
       "      <th>imdb_plot</th>\n",
       "      <th>popularity</th>\n",
       "      <th>release_date</th>\n",
       "      <th>...</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "      <th>tmdb_clean_plot</th>\n",
       "      <th>imdb_clean_plot</th>\n",
       "      <th>tmdb_w2v_plot</th>\n",
       "      <th>imdb_w2v_plot</th>\n",
       "      <th>tmdb_bow_plot</th>\n",
       "      <th>imdb_bow_plot</th>\n",
       "      <th>combined_plots</th>\n",
       "      <th>combined_bow_plots</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>278</td>\n",
       "      <td>tt0111161</td>\n",
       "      <td>[18, 80]</td>\n",
       "      <td>[80, 18]</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...</td>\n",
       "      <td>Framed in the 1940s for the double murder of h...</td>\n",
       "      <td>Chronicles the experiences of a formerly succe...</td>\n",
       "      <td>28.527767</td>\n",
       "      <td>1994-09-23</td>\n",
       "      <td>...</td>\n",
       "      <td>8.5</td>\n",
       "      <td>9773</td>\n",
       "      <td>['framed', '1940s', 'double', 'murder', 'wife'...</td>\n",
       "      <td>['chronicles', 'experiences', 'formerly', 'suc...</td>\n",
       "      <td>[0.014165705069899559, 0.035729147493839264, 0...</td>\n",
       "      <td>[0.004663567990064621, 0.09018586575984955, -0...</td>\n",
       "      <td>(0, 700)\\t0.1914190824267342\\n  (0, 1141)\\t0...</td>\n",
       "      <td>(0, 398)\\t0.22753905256972778\\n  (0, 759)\\t0...</td>\n",
       "      <td>Framed in the 1940s for the double murder of h...</td>\n",
       "      <td>(0, 1092)\\t0.15089615016031976\\n  (0, 811)\\t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>238</td>\n",
       "      <td>tt0068646</td>\n",
       "      <td>[18, 80]</td>\n",
       "      <td>[80, 18]</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...</td>\n",
       "      <td>Spanning the years 1945 to 1955  a chronicle o...</td>\n",
       "      <td>When the aging head of a famous crime family d...</td>\n",
       "      <td>36.965452</td>\n",
       "      <td>1972-03-14</td>\n",
       "      <td>...</td>\n",
       "      <td>8.5</td>\n",
       "      <td>7394</td>\n",
       "      <td>['spanning', 'years', '1945', '1955', 'chronic...</td>\n",
       "      <td>['aging', 'head', 'famous', 'crime', 'family',...</td>\n",
       "      <td>[-0.016820836812257767, 0.05966977775096893, -...</td>\n",
       "      <td>[-0.013326308690011501, 0.08134819567203522, 0...</td>\n",
       "      <td>(0, 610)\\t0.12626163649598618\\n  (0, 1165)\\t...</td>\n",
       "      <td>(0, 515)\\t0.17259715509464205\\n  (0, 938)\\t0...</td>\n",
       "      <td>Spanning the years 1945 to 1955  a chronicle o...</td>\n",
       "      <td>(0, 1773)\\t0.10485484905546055\\n  (0, 287)\\t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>424</td>\n",
       "      <td>tt0108052</td>\n",
       "      <td>[18, 36, 10752]</td>\n",
       "      <td>[18, 36]</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>The true story of how businessman Oskar Schind...</td>\n",
       "      <td>Oskar Schindler is a vainglorious and greedy G...</td>\n",
       "      <td>19.945455</td>\n",
       "      <td>1993-11-29</td>\n",
       "      <td>...</td>\n",
       "      <td>8.4</td>\n",
       "      <td>5518</td>\n",
       "      <td>['true', 'story', 'businessman', 'oskar', 'sch...</td>\n",
       "      <td>['oskar', 'schindler', 'vainglorious', 'greedy...</td>\n",
       "      <td>[0.0758906751871109, 0.02254812978208065, 0.06...</td>\n",
       "      <td>[0.05338115245103836, 0.10281133651733398, 0.0...</td>\n",
       "      <td>(0, 1079)\\t0.2907037443234484\\n  (0, 990)\\t0...</td>\n",
       "      <td>(0, 916)\\t0.40896979889639457\\n  (0, 317)\\t0...</td>\n",
       "      <td>The true story of how businessman Oskar Schind...</td>\n",
       "      <td>(0, 2911)\\t0.09695795170181548\\n  (0, 2774)\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>240</td>\n",
       "      <td>tt0071562</td>\n",
       "      <td>[18, 80]</td>\n",
       "      <td>[80, 18]</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...</td>\n",
       "      <td>In the continuing saga of the Corleone crime f...</td>\n",
       "      <td>The continuing saga of the Corleone crime fami...</td>\n",
       "      <td>30.191804</td>\n",
       "      <td>1974-12-20</td>\n",
       "      <td>...</td>\n",
       "      <td>8.4</td>\n",
       "      <td>4249</td>\n",
       "      <td>['continuing', 'saga', 'corleone', 'crime', 'f...</td>\n",
       "      <td>['continuing', 'saga', 'corleone', 'crime', 'f...</td>\n",
       "      <td>[-0.05790800228714943, 0.07111673057079315, -0...</td>\n",
       "      <td>[-0.05151921883225441, 0.07896284759044647, -0...</td>\n",
       "      <td>(0, 720)\\t0.19462813339213522\\n  (0, 243)\\t0...</td>\n",
       "      <td>(0, 515)\\t0.21968270215051702\\n  (0, 1494)\\t...</td>\n",
       "      <td>In the continuing saga of the Corleone crime f...</td>\n",
       "      <td>(0, 1821)\\t0.12839540573874353\\n  (0, 649)\\t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>452522</td>\n",
       "      <td>tt0278784</td>\n",
       "      <td>[18, 9648]</td>\n",
       "      <td>[80, 18, 9648, 53]</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, ...</td>\n",
       "      <td>Standalone version of the series pilot with an...</td>\n",
       "      <td>When beautiful  young Laura Palmer is found br...</td>\n",
       "      <td>5.969249</td>\n",
       "      <td>1989-12-31</td>\n",
       "      <td>...</td>\n",
       "      <td>8.4</td>\n",
       "      <td>123</td>\n",
       "      <td>['standalone', 'version', 'series', 'pilot', '...</td>\n",
       "      <td>['beautiful', 'young', 'laura', 'palmer', 'fou...</td>\n",
       "      <td>[-0.05888228118419647, -0.05345569923520088, -...</td>\n",
       "      <td>[0.0026558770332485437, 0.10140948742628098, 0...</td>\n",
       "      <td>(0, 1110)\\t0.5243217302828199\\n  (0, 925)\\t0...</td>\n",
       "      <td>(0, 875)\\t0.15459130001922888\\n  (0, 2438)\\t...</td>\n",
       "      <td>Standalone version of the series pilot with an...</td>\n",
       "      <td>(0, 1088)\\t0.12464518166470029\\n  (0, 2380)\\...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   tmdb_id    imdb_id      tmdb_genres         imdb_genres  \\\n",
       "0      278  tt0111161         [18, 80]            [80, 18]   \n",
       "1      238  tt0068646         [18, 80]            [80, 18]   \n",
       "2      424  tt0108052  [18, 36, 10752]            [18, 36]   \n",
       "3      240  tt0071562         [18, 80]            [80, 18]   \n",
       "4   452522  tt0278784       [18, 9648]  [80, 18, 9648, 53]   \n",
       "\n",
       "                                         binary_tmdb  \\\n",
       "0  [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...   \n",
       "1  [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...   \n",
       "2  [0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3  [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...   \n",
       "4  [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, ...   \n",
       "\n",
       "                                         binary_imdb  \\\n",
       "0  [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...   \n",
       "1  [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...   \n",
       "2  [0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3  [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...   \n",
       "4  [0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, ...   \n",
       "\n",
       "                                           tmdb_plot  \\\n",
       "0  Framed in the 1940s for the double murder of h...   \n",
       "1  Spanning the years 1945 to 1955  a chronicle o...   \n",
       "2  The true story of how businessman Oskar Schind...   \n",
       "3  In the continuing saga of the Corleone crime f...   \n",
       "4  Standalone version of the series pilot with an...   \n",
       "\n",
       "                                           imdb_plot  popularity release_date  \\\n",
       "0  Chronicles the experiences of a formerly succe...   28.527767   1994-09-23   \n",
       "1  When the aging head of a famous crime family d...   36.965452   1972-03-14   \n",
       "2  Oskar Schindler is a vainglorious and greedy G...   19.945455   1993-11-29   \n",
       "3  The continuing saga of the Corleone crime fami...   30.191804   1974-12-20   \n",
       "4  When beautiful  young Laura Palmer is found br...    5.969249   1989-12-31   \n",
       "\n",
       "                         ...                         vote_average  vote_count  \\\n",
       "0                        ...                                  8.5        9773   \n",
       "1                        ...                                  8.5        7394   \n",
       "2                        ...                                  8.4        5518   \n",
       "3                        ...                                  8.4        4249   \n",
       "4                        ...                                  8.4         123   \n",
       "\n",
       "                                     tmdb_clean_plot  \\\n",
       "0  ['framed', '1940s', 'double', 'murder', 'wife'...   \n",
       "1  ['spanning', 'years', '1945', '1955', 'chronic...   \n",
       "2  ['true', 'story', 'businessman', 'oskar', 'sch...   \n",
       "3  ['continuing', 'saga', 'corleone', 'crime', 'f...   \n",
       "4  ['standalone', 'version', 'series', 'pilot', '...   \n",
       "\n",
       "                                     imdb_clean_plot  \\\n",
       "0  ['chronicles', 'experiences', 'formerly', 'suc...   \n",
       "1  ['aging', 'head', 'famous', 'crime', 'family',...   \n",
       "2  ['oskar', 'schindler', 'vainglorious', 'greedy...   \n",
       "3  ['continuing', 'saga', 'corleone', 'crime', 'f...   \n",
       "4  ['beautiful', 'young', 'laura', 'palmer', 'fou...   \n",
       "\n",
       "                                       tmdb_w2v_plot  \\\n",
       "0  [0.014165705069899559, 0.035729147493839264, 0...   \n",
       "1  [-0.016820836812257767, 0.05966977775096893, -...   \n",
       "2  [0.0758906751871109, 0.02254812978208065, 0.06...   \n",
       "3  [-0.05790800228714943, 0.07111673057079315, -0...   \n",
       "4  [-0.05888228118419647, -0.05345569923520088, -...   \n",
       "\n",
       "                                       imdb_w2v_plot  \\\n",
       "0  [0.004663567990064621, 0.09018586575984955, -0...   \n",
       "1  [-0.013326308690011501, 0.08134819567203522, 0...   \n",
       "2  [0.05338115245103836, 0.10281133651733398, 0.0...   \n",
       "3  [-0.05151921883225441, 0.07896284759044647, -0...   \n",
       "4  [0.0026558770332485437, 0.10140948742628098, 0...   \n",
       "\n",
       "                                       tmdb_bow_plot  \\\n",
       "0    (0, 700)\\t0.1914190824267342\\n  (0, 1141)\\t0...   \n",
       "1    (0, 610)\\t0.12626163649598618\\n  (0, 1165)\\t...   \n",
       "2    (0, 1079)\\t0.2907037443234484\\n  (0, 990)\\t0...   \n",
       "3    (0, 720)\\t0.19462813339213522\\n  (0, 243)\\t0...   \n",
       "4    (0, 1110)\\t0.5243217302828199\\n  (0, 925)\\t0...   \n",
       "\n",
       "                                       imdb_bow_plot  \\\n",
       "0    (0, 398)\\t0.22753905256972778\\n  (0, 759)\\t0...   \n",
       "1    (0, 515)\\t0.17259715509464205\\n  (0, 938)\\t0...   \n",
       "2    (0, 916)\\t0.40896979889639457\\n  (0, 317)\\t0...   \n",
       "3    (0, 515)\\t0.21968270215051702\\n  (0, 1494)\\t...   \n",
       "4    (0, 875)\\t0.15459130001922888\\n  (0, 2438)\\t...   \n",
       "\n",
       "                                      combined_plots  \\\n",
       "0  Framed in the 1940s for the double murder of h...   \n",
       "1  Spanning the years 1945 to 1955  a chronicle o...   \n",
       "2  The true story of how businessman Oskar Schind...   \n",
       "3  In the continuing saga of the Corleone crime f...   \n",
       "4  Standalone version of the series pilot with an...   \n",
       "\n",
       "                                  combined_bow_plots  \n",
       "0    (0, 1092)\\t0.15089615016031976\\n  (0, 811)\\t...  \n",
       "1    (0, 1773)\\t0.10485484905546055\\n  (0, 287)\\t...  \n",
       "2    (0, 2911)\\t0.09695795170181548\\n  (0, 2774)\\...  \n",
       "3    (0, 1821)\\t0.12839540573874353\\n  (0, 649)\\t...  \n",
       "4    (0, 1088)\\t0.12464518166470029\\n  (0, 2380)\\...  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read in dataset\n",
    "movies = pd.read_csv('Data/movies.csv', encoding='utf8', \n",
    "                     converters={'tmdb_genres':literal_eval, 'imdb_genres':literal_eval})\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Make new feature of combined TMDB and IMDB plots\n",
    "We will make a new column with the combined plots of tmdb and imdb. Perhaps this will offer a richer representation of each plot and increase our precision and recall in the forthcoming modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "movies['combined_plots'] = movies['tmdb_plot'] + ' ' + movies['imdb_plot']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Clean plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "174"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define tokenizer\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "#set stop words list\n",
    "english_stop = get_stop_words('en')\n",
    "len(english_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#function to clean plots\n",
    "def clean_plot(plot):\n",
    "    plot = plot.lower()\n",
    "    plot = tokenizer.tokenize(plot)\n",
    "    plot = [word for word in plot if word not in english_stop]\n",
    "    return plot\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Framed in the 1940s for the double murder of his wife and her lover  upstanding banker Andy Dufresne begins a new life at the Shawshank prison  where he puts his accounting skills to work for an amoral warden  During his long stretch in prison  Dufresne comes to be admired by the other inmates    including an older prisoner named Red    for his integrity and unquenchable sense of hope\n",
      "['framed', '1940s', 'double', 'murder', 'wife', 'lover', 'upstanding', 'banker', 'andy', 'dufresne', 'begins', 'new', 'life', 'shawshank', 'prison', 'puts', 'accounting', 'skills', 'work', 'amoral', 'warden', 'long', 'stretch', 'prison', 'dufresne', 'comes', 'admired', 'inmates', 'including', 'older', 'prisoner', 'named', 'red', 'integrity', 'unquenchable', 'sense', 'hope']\n"
     ]
    }
   ],
   "source": [
    "#check first movie's clean plot\n",
    "print(movies.tmdb_plot[0])\n",
    "print(clean_plot(movies.tmdb_plot[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#apply to movies df for both imdb and tmdb\n",
    "movies['tmdb_clean_plot'] = movies['tmdb_plot'].apply(lambda x: clean_plot(x))\n",
    "movies['imdb_clean_plot'] = movies['imdb_plot'].apply(lambda x: clean_plot(x))\n",
    "movies['combined_clean_plot'] = movies['combined_plots'].apply(lambda x: clean_plot(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    [spanning, years, 1945, 1955, chronicle, ficti...\n",
       "2    [true, story, businessman, oskar, schindler, s...\n",
       "3    [continuing, saga, corleone, crime, family, yo...\n",
       "4    [standalone, version, series, pilot, alternate...\n",
       "Name: tmdb_clean_plot, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check some outputs\n",
    "movies.tmdb_clean_plot[1:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Apply word2vec Transformation of Plots\n",
    "\n",
    "For this transformation we will use the Google News pretrained word2vec model that was trained on a more than 3 billion word corpus. It contains 3 million words, each represented by a 300-dimension vector. We make a couple of design choices for how we transform our movie plots:\n",
    "\n",
    "- If a word in the cleaned plots (lowered, punctuation and stop word dropped, tokenized) is in the word2vec model, add it to a running list for that plot.\n",
    "- If a word is not in the word2vec model, skip it. We print some of these words below for example.\n",
    "- We then take two different representations for each plot. One as a matrix where each row is a 300-dimension representation of a particular word in the plot, and a column-wise mean vector, where each plot is reduced to 1x300 dimension array.\n",
    "\n",
    "The assumption we make by taking the mean of each plot is that the resulting 300-dimension vector will point in the direction of one or more genres, but we acknowledge that it will most likely reduce some of the semantic value of certain words.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load the pretrained google news word2vec model\n",
    "model = models.KeyedVectors.load_word2vec_format('data/GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#collect words not in the Google News w2v model\n",
    "not_w2v = []\n",
    "\n",
    "#word2vec function\n",
    "def apply_words2Vec(cleaned_plot, mean=False):\n",
    "    \n",
    "    \"\"\"\n",
    "    apply_words2Vec()\n",
    "    -applies the following transformations to the cleaned plot of a movie:\n",
    "        1) removes words that are not in google's model\n",
    "        2) creates a 300-dimension vector representation of each word\n",
    "        3) outputes vector of vectors for plot\n",
    "        If mean = True\n",
    "        4) converts the resulting nd_array into a 1d_array via np.mean() and\n",
    "           outputs single vector for each plot.\n",
    "    -also keeps track of all words not found in google's model\n",
    "    \n",
    "    -inputs: cleaned_plot (string)\n",
    "    \n",
    "    -outputs: vector representation of plot\n",
    "    \n",
    "    \"\"\"\n",
    "    vecs=[]\n",
    "    for word in cleaned_plot:\n",
    "        #add word vector to list if it is in the google model\n",
    "        try:\n",
    "            vecs.append(model.word_vec(word)) \n",
    "        except:\n",
    "            #if the word is not in the w2v model, add it to\n",
    "            #our list of skipped words\n",
    "            not_w2v.append(word)\n",
    "    \n",
    "    #take the column-wise mean of vecs to reduce nd_aray to 1d_array\n",
    "    if mean == True:\n",
    "        vecs = np.mean(vecs, axis=0)\n",
    "        return vecs\n",
    "    #return matrix of w2v arrays where each row is a word in the plot\n",
    "    return np.stack(vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#apply transformation to three sets of plots and add columns to df\n",
    "\n",
    "#columns with mean w2v\n",
    "movies['tmdb_w2v_plot_mean'] = movies['tmdb_clean_plot'].apply(lambda x: apply_words2Vec(x, mean=True))\n",
    "movies['imdb_w2v_plot_mean'] = movies['imdb_clean_plot'].apply(lambda x: apply_words2Vec(x, mean=True))\n",
    "movies['combined_w2v_plot_mean'] = movies['combined_clean_plot'].apply(lambda x: apply_words2Vec(x, mean=True))\n",
    "\n",
    "#columns with w2v matrix for each plot\n",
    "movies['tmdb_w2v_plot_matrix'] = movies['tmdb_clean_plot'].apply(lambda x: apply_words2Vec(x, mean=False))\n",
    "movies['imdb_w2v_plot_matrix'] = movies['imdb_clean_plot'].apply(lambda x: apply_words2Vec(x, mean=False))\n",
    "movies['combined_w2v_plot_matrix'] = movies['combined_clean_plot'].apply(lambda x: apply_words2Vec(x, mean=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean vector representations:\n",
      "(300,) (300,) (300,)\n",
      "Matrix representations:\n",
      "(33, 300) (38, 300) (71, 300)\n"
     ]
    }
   ],
   "source": [
    "#check shapes of first movie vectors to confirm nd_array and 300-dimensions\n",
    "print('Mean vector representations:')\n",
    "print(movies.loc[0,'tmdb_w2v_plot_mean'].shape, \n",
    "      movies.loc[0,'imdb_w2v_plot_mean'].shape, \n",
    "      movies.loc[0, 'combined_w2v_plot_mean'].shape)\n",
    "\n",
    "print('Matrix representations:')\n",
    "print(movies.loc[0,'tmdb_w2v_plot_matrix'].shape, \n",
    "      movies.loc[0,'imdb_w2v_plot_matrix'].shape,\n",
    "      movies.loc[0,'combined_w2v_plot_matrix'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each TMDB and IMDB plot has been transformed into a 300-dimension representation of that plot, as well as an matrix where each row represents a word in the plot. We will use these features as predictors in our multi-lable classification modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21664\n",
      "['dunkirk' 'cambodian' 'kowalski' 'beale' 'matlock' 'cinema_fan' 'ronan'\n",
      " 'katniss' 'leia' 'halley' 'simon_hrdng' 'willem' 'mimmo' 'barnum'\n",
      " 'bennet' 'elsa' 'trinh' 'tyrone' 'wigand' 'dufresne' '1879' '22' 'huggo'\n",
      " '000' 'claudio' 'spurlin' '15' 'jwelch5742' 'krueger' '500' 'bergman'\n",
      " 'cellini' 'kyla' 'andrewhodkinson' '1976' 'yvette' 'hiddleston' 'salieri'\n",
      " 'huggo' '1980s' 'turturro' 'cambodia' 'fleetwood' '1900' 'redondo'\n",
      " 'peatty' 'film_fan' 'bonneville' 'gooper' '000']\n"
     ]
    }
   ],
   "source": [
    "#print some of our skipped words\n",
    "print(len(not_w2v))\n",
    "np.random.seed(112)\n",
    "print(np.random.choice(not_w2v, 50, replace=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 21664 words in our cleaned TMDB and IMDB plots that were skipped when applying the word2vec transformation (some are repeats due to combined plots). As seen above, the random sample of 50 of those words are mostly years, numbers, and proper nouns. This is not surprising, and we suspect will not have a large impact on the resulting word2vec representations of our movie plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All TMDB movies have a word2vec representation.\n",
      "All IMDB movies have a word2vec representation.\n"
     ]
    }
   ],
   "source": [
    "#check that each plot has a corresponding word2vec representation\n",
    "#if both TMDB and IMDB have mean representations, we can assume\n",
    "#the combined and matrix representations are also filled\n",
    "for plot in movies.tmdb_w2v_plot_mean:\n",
    "    if len(plot) != 300:\n",
    "        print(\"AH! no word2vec representation\")\n",
    "print('All TMDB movies have a word2vec representation.')\n",
    "\n",
    "for plot in movies.imdb_w2v_plot_mean:\n",
    "    if len(plot) != 300:\n",
    "        print(\"AH! no word2vec representation\")\n",
    "print('All IMDB movies have a word2vec representation.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save w2v data as a numpy arrays/matrices for further modeling and analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#w2v mean vectors\n",
    "np.save('data/tmdb_w2v_mean.npy', movies['tmdb_w2v_plot_mean'].as_matrix())\n",
    "np.save('data/imdb_w2v_mean.npy', movies['imdb_w2v_plot_mean'].as_matrix())\n",
    "np.save('data/combined_w2v_mean.npy', movies['combined_w2v_plot_mean'].as_matrix())\n",
    "\n",
    "#w2v matrices\n",
    "np.save('data/tmdb_w2v_matrix.npy', movies['tmdb_w2v_plot_matrix'].as_matrix())\n",
    "np.save('data/imdb_w2v_matrix.npy', movies['imdb_w2v_plot_matrix'].as_matrix())\n",
    "np.save('data/combined_w2v_matrix.npy', movies['combined_w2v_plot_matrix'].as_matrix())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Update and save DataFrame for future analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.to_csv('data/movies.csv', encoding=\"utf-8\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We have now transformed and saved each plot as a 300-dimension vector and n_words x 300 dimension matrix word2vec representation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
