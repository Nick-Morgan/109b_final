{"Naive-Bayes-tmdb_bow": {"fitted_model": null, "train_yhat": null, "test_yhat": null, "train_recall_score": 0.6115765422696116, "test_recall_score": 0.3158756137479542, "train_precision_score": 0.8259320036058125, "test_precision_score": 0.4980420149295266, "train_classification_report": "             precision    recall  f1-score   support\n\n          0       1.00      0.08      0.15        88\n          1       1.00      0.73      0.84        55\n          2       1.00      0.85      0.92        52\n          3       0.83      1.00      0.90       327\n          4       1.00      0.96      0.98        26\n          5       1.00      0.08      0.15        84\n          6       1.00      0.14      0.25       121\n          7       0.00      0.00      0.00        39\n          8       1.00      0.73      0.84        11\n          9       0.98      0.85      0.91       112\n         10       0.99      0.88      0.93        93\n         11       0.00      0.00      0.00        52\n         12       1.00      0.89      0.94        55\n         13       1.00      0.71      0.83        24\n         14       0.00      0.00      0.00        77\n         15       1.00      0.86      0.93        59\n         16       1.00      0.91      0.96        35\n         17       1.00      1.00      1.00         3\n\navg / total       0.83      0.61      0.63      1313\n", "test_classification_report": "             precision    recall  f1-score   support\n\n          0       1.00      0.04      0.07        79\n          1       0.36      0.11      0.16        38\n          2       0.80      0.09      0.16        46\n          3       0.65      0.98      0.78       316\n          4       0.00      0.00      0.00        26\n          5       0.00      0.00      0.00        82\n          6       0.67      0.02      0.03       115\n          7       0.00      0.00      0.00        33\n          8       0.00      0.00      0.00        22\n          9       0.58      0.22      0.32       112\n         10       0.67      0.27      0.38        83\n         11       0.00      0.00      0.00        54\n         12       0.40      0.04      0.08        45\n         13       0.00      0.00      0.00        20\n         14       0.00      0.00      0.00        71\n         15       0.62      0.15      0.25        52\n         16       1.00      0.28      0.44        25\n         17       0.00      0.00      0.00         3\n\navg / total       0.50      0.32      0.30      1222\n"}, "Naive-Bayes-imdb_bow": {"fitted_model": null, "train_yhat": null, "test_yhat": null, "train_recall_score": 0.8278750952018279, "test_recall_score": 0.30523731587561376, "train_precision_score": 0.9375661204184481, "test_precision_score": 0.5402471190934137, "train_classification_report": "             precision    recall  f1-score   support\n\n          0       0.99      0.99      0.99        88\n          1       1.00      0.95      0.97        55\n          2       1.00      1.00      1.00        52\n          3       0.99      0.99      0.99       327\n          4       1.00      1.00      1.00        26\n          5       1.00      0.87      0.93        84\n          6       1.00      0.04      0.08       121\n          7       1.00      1.00      1.00        39\n          8       1.00      1.00      1.00        11\n          9       1.00      0.98      0.99       112\n         10       1.00      0.92      0.96        93\n         11       1.00      1.00      1.00        52\n         12       1.00      0.95      0.97        55\n         13       1.00      0.88      0.93        24\n         14       0.00      0.00      0.00        77\n         15       1.00      1.00      1.00        59\n         16       1.00      0.97      0.99        35\n         17       1.00      1.00      1.00         3\n\navg / total       0.94      0.83      0.84      1313\n", "test_classification_report": "             precision    recall  f1-score   support\n\n          0       0.83      0.13      0.22        79\n          1       0.83      0.13      0.23        38\n          2       1.00      0.07      0.12        46\n          3       0.72      0.90      0.80       316\n          4       0.00      0.00      0.00        26\n          5       0.63      0.21      0.31        82\n          6       0.00      0.00      0.00       115\n          7       0.00      0.00      0.00        33\n          8       0.00      0.00      0.00        22\n          9       0.46      0.11      0.17       112\n         10       0.68      0.25      0.37        83\n         11       1.00      0.11      0.20        54\n         12       0.17      0.02      0.04        45\n         13       0.00      0.00      0.00        20\n         14       0.00      0.00      0.00        71\n         15       0.89      0.15      0.26        52\n         16       0.83      0.20      0.32        25\n         17       0.00      0.00      0.00         3\n\navg / total       0.54      0.31      0.32      1222\n"}, "Naive-Bayes-combined_bow": {"fitted_model": null, "train_yhat": null, "test_yhat": null, "train_recall_score": 0.884996191926885, "test_recall_score": 0.34942716857610473, "train_precision_score": 0.9953622114769265, "test_precision_score": 0.6262068278148474, "train_classification_report": "             precision    recall  f1-score   support\n\n          0       0.99      0.98      0.98        88\n          1       1.00      0.91      0.95        55\n          2       1.00      1.00      1.00        52\n          3       0.99      1.00      0.99       327\n          4       1.00      1.00      1.00        26\n          5       1.00      0.99      0.99        84\n          6       1.00      0.03      0.06       121\n          7       0.97      0.87      0.92        39\n          8       1.00      1.00      1.00        11\n          9       1.00      0.94      0.97       112\n         10       1.00      0.96      0.98        93\n         11       1.00      1.00      1.00        52\n         12       1.00      0.96      0.98        55\n         13       1.00      1.00      1.00        24\n         14       1.00      0.97      0.99        77\n         15       1.00      0.97      0.98        59\n         16       1.00      0.91      0.96        35\n         17       1.00      1.00      1.00         3\n\navg / total       1.00      0.88      0.90      1313\n", "test_classification_report": "             precision    recall  f1-score   support\n\n          0       0.88      0.27      0.41        79\n          1       0.67      0.16      0.26        38\n          2       1.00      0.11      0.20        46\n          3       0.73      0.91      0.81       316\n          4       0.00      0.00      0.00        26\n          5       0.68      0.21      0.32        82\n          6       0.00      0.00      0.00       115\n          7       0.50      0.03      0.06        33\n          8       0.00      0.00      0.00        22\n          9       0.57      0.21      0.31       112\n         10       0.72      0.34      0.46        83\n         11       0.75      0.11      0.19        54\n         12       0.83      0.11      0.20        45\n         13       0.00      0.00      0.00        20\n         14       0.80      0.06      0.11        71\n         15       0.77      0.19      0.31        52\n         16       0.92      0.44      0.59        25\n         17       0.00      0.00      0.00         3\n\navg / total       0.63      0.35      0.38      1222\n"}, "Naive-Bayes-tmdb_w2v_mean": {"fitted_model": null, "train_yhat": null, "test_yhat": null, "train_recall_score": 0.25894897182025894, "test_recall_score": 0.26595744680851063, "train_precision_score": 0.5237290555978675, "test_precision_score": 0.33057229917634695, "train_classification_report": "             precision    recall  f1-score   support\n\n          0       1.00      0.01      0.02        88\n          1       0.00      0.00      0.00        55\n          2       0.00      0.00      0.00        52\n          3       0.68      0.99      0.81       327\n          4       0.00      0.00      0.00        26\n          5       1.00      0.01      0.02        84\n          6       0.00      0.00      0.00       121\n          7       0.00      0.00      0.00        39\n          8       1.00      0.09      0.17        11\n          9       1.00      0.04      0.09       112\n         10       1.00      0.03      0.06        93\n         11       1.00      0.02      0.04        52\n         12       0.00      0.00      0.00        55\n         13       0.00      0.00      0.00        24\n         14       0.00      0.00      0.00        77\n         15       0.00      0.00      0.00        59\n         16       0.75      0.09      0.15        35\n         17       0.00      0.00      0.00         3\n\navg / total       0.52      0.26      0.22      1313\n", "test_classification_report": "             precision    recall  f1-score   support\n\n          0       0.00      0.00      0.00        79\n          1       0.00      0.00      0.00        38\n          2       0.00      0.00      0.00        46\n          3       0.64      1.00      0.78       316\n          4       0.00      0.00      0.00        26\n          5       0.00      0.00      0.00        82\n          6       0.00      0.00      0.00       115\n          7       0.00      0.00      0.00        33\n          8       0.00      0.00      0.00        22\n          9       0.80      0.04      0.07       112\n         10       0.80      0.05      0.09        83\n         11       0.00      0.00      0.00        54\n         12       1.00      0.02      0.04        45\n         13       0.00      0.00      0.00        20\n         14       0.00      0.00      0.00        71\n         15       0.00      0.00      0.00        52\n         16       0.00      0.00      0.00        25\n         17       0.00      0.00      0.00         3\n\navg / total       0.33      0.27      0.22      1222\n"}, "Naive-Bayes-imdb_w2v_mean": {"fitted_model": null, "train_yhat": null, "test_yhat": null, "train_recall_score": 0.25666412795125665, "test_recall_score": 0.26677577741407527, "train_precision_score": 0.5569963495023242, "test_precision_score": 0.412309883653247, "train_classification_report": "             precision    recall  f1-score   support\n\n          0       1.00      0.01      0.02        88\n          1       0.00      0.00      0.00        55\n          2       0.00      0.00      0.00        52\n          3       0.70      0.99      0.82       327\n          4       0.00      0.00      0.00        26\n          5       1.00      0.01      0.02        84\n          6       0.00      0.00      0.00       121\n          7       1.00      0.03      0.05        39\n          8       0.00      0.00      0.00        11\n          9       1.00      0.01      0.02       112\n         10       1.00      0.01      0.02        93\n         11       1.00      0.04      0.07        52\n         12       0.00      0.00      0.00        55\n         13       0.00      0.00      0.00        24\n         14       0.00      0.00      0.00        77\n         15       0.00      0.00      0.00        59\n         16       1.00      0.17      0.29        35\n         17       0.00      0.00      0.00         3\n\navg / total       0.56      0.26      0.22      1313\n", "test_classification_report": "             precision    recall  f1-score   support\n\n          0       0.00      0.00      0.00        79\n          1       0.00      0.00      0.00        38\n          2       1.00      0.02      0.04        46\n          3       0.66      1.00      0.79       316\n          4       0.00      0.00      0.00        26\n          5       0.00      0.00      0.00        82\n          6       0.00      0.00      0.00       115\n          7       0.00      0.00      0.00        33\n          8       0.00      0.00      0.00        22\n          9       0.80      0.04      0.07       112\n         10       1.00      0.04      0.07        83\n         11       0.00      0.00      0.00        54\n         12       0.00      0.00      0.00        45\n         13       0.00      0.00      0.00        20\n         14       0.00      0.00      0.00        71\n         15       1.00      0.02      0.04        52\n         16       1.00      0.08      0.15        25\n         17       0.00      0.00      0.00         3\n\navg / total       0.41      0.27      0.22      1222\n"}, "Naive-Bayes-combined_w2v_mean": {"fitted_model": null, "train_yhat": null, "test_yhat": null, "train_recall_score": 0.2718964204112719, "test_recall_score": 0.279050736497545, "train_precision_score": 0.6154805912110911, "test_precision_score": 0.529128013541882, "train_classification_report": "             precision    recall  f1-score   support\n\n          0       0.50      0.05      0.08        88\n          1       1.00      0.05      0.10        55\n          2       1.00      0.02      0.04        52\n          3       0.71      0.98      0.82       327\n          4       0.00      0.00      0.00        26\n          5       0.83      0.06      0.11        84\n          6       0.00      0.00      0.00       121\n          7       1.00      0.03      0.05        39\n          8       0.00      0.00      0.00        11\n          9       0.83      0.04      0.08       112\n         10       0.83      0.05      0.10        93\n         11       1.00      0.10      0.18        52\n         12       0.00      0.00      0.00        55\n         13       0.00      0.00      0.00        24\n         14       0.00      0.00      0.00        77\n         15       1.00      0.02      0.03        59\n         16       1.00      0.23      0.37        35\n         17       0.00      0.00      0.00         3\n\navg / total       0.62      0.27      0.26      1313\n", "test_classification_report": "             precision    recall  f1-score   support\n\n          0       1.00      0.01      0.02        79\n          1       0.00      0.00      0.00        38\n          2       1.00      0.02      0.04        46\n          3       0.67      0.99      0.80       316\n          4       0.00      0.00      0.00        26\n          5       0.00      0.00      0.00        82\n          6       0.00      0.00      0.00       115\n          7       0.00      0.00      0.00        33\n          8       0.00      0.00      0.00        22\n          9       0.90      0.08      0.15       112\n         10       1.00      0.11      0.20        83\n         11       1.00      0.06      0.11        54\n         12       0.00      0.00      0.00        45\n         13       0.00      0.00      0.00        20\n         14       0.00      0.00      0.00        71\n         15       1.00      0.02      0.04        52\n         16       0.80      0.16      0.27        25\n         17       0.00      0.00      0.00         3\n\navg / total       0.53      0.28      0.25      1222\n"}, "SGD-tmdb_bow": {"fitted_model": null, "train_yhat": null, "test_yhat": null, "train_recall_score": 0.24904798172124903, "test_recall_score": 0.25859247135842883, "train_precision_score": 0.16287738004569688, "test_precision_score": 0.16343044189852698, "train_classification_report": "             precision    recall  f1-score   support\n\n          0       0.00      0.00      0.00        88\n          1       0.00      0.00      0.00        55\n          2       0.00      0.00      0.00        52\n          3       0.65      1.00      0.79       327\n          4       0.00      0.00      0.00        26\n          5       0.00      0.00      0.00        84\n          6       0.00      0.00      0.00       121\n          7       0.00      0.00      0.00        39\n          8       0.00      0.00      0.00        11\n          9       0.00      0.00      0.00       112\n         10       0.00      0.00      0.00        93\n         11       0.00      0.00      0.00        52\n         12       0.00      0.00      0.00        55\n         13       0.00      0.00      0.00        24\n         14       0.00      0.00      0.00        77\n         15       0.00      0.00      0.00        59\n         16       0.00      0.00      0.00        35\n         17       0.00      0.00      0.00         3\n\navg / total       0.16      0.25      0.20      1313\n", "test_classification_report": "             precision    recall  f1-score   support\n\n          0       0.00      0.00      0.00        79\n          1       0.00      0.00      0.00        38\n          2       0.00      0.00      0.00        46\n          3       0.63      1.00      0.77       316\n          4       0.00      0.00      0.00        26\n          5       0.00      0.00      0.00        82\n          6       0.00      0.00      0.00       115\n          7       0.00      0.00      0.00        33\n          8       0.00      0.00      0.00        22\n          9       0.00      0.00      0.00       112\n         10       0.00      0.00      0.00        83\n         11       0.00      0.00      0.00        54\n         12       0.00      0.00      0.00        45\n         13       0.00      0.00      0.00        20\n         14       0.00      0.00      0.00        71\n         15       0.00      0.00      0.00        52\n         16       0.00      0.00      0.00        25\n         17       0.00      0.00      0.00         3\n\navg / total       0.16      0.26      0.20      1222\n"}, "SGD-imdb_bow": {"fitted_model": null, "train_yhat": null, "test_yhat": null, "train_recall_score": 0.24904798172124903, "test_recall_score": 0.25859247135842883, "train_precision_score": 0.16287738004569688, "test_precision_score": 0.16343044189852698, "train_classification_report": "             precision    recall  f1-score   support\n\n          0       0.00      0.00      0.00        88\n          1       0.00      0.00      0.00        55\n          2       0.00      0.00      0.00        52\n          3       0.65      1.00      0.79       327\n          4       0.00      0.00      0.00        26\n          5       0.00      0.00      0.00        84\n          6       0.00      0.00      0.00       121\n          7       0.00      0.00      0.00        39\n          8       0.00      0.00      0.00        11\n          9       0.00      0.00      0.00       112\n         10       0.00      0.00      0.00        93\n         11       0.00      0.00      0.00        52\n         12       0.00      0.00      0.00        55\n         13       0.00      0.00      0.00        24\n         14       0.00      0.00      0.00        77\n         15       0.00      0.00      0.00        59\n         16       0.00      0.00      0.00        35\n         17       0.00      0.00      0.00         3\n\navg / total       0.16      0.25      0.20      1313\n", "test_classification_report": "             precision    recall  f1-score   support\n\n          0       0.00      0.00      0.00        79\n          1       0.00      0.00      0.00        38\n          2       0.00      0.00      0.00        46\n          3       0.63      1.00      0.77       316\n          4       0.00      0.00      0.00        26\n          5       0.00      0.00      0.00        82\n          6       0.00      0.00      0.00       115\n          7       0.00      0.00      0.00        33\n          8       0.00      0.00      0.00        22\n          9       0.00      0.00      0.00       112\n         10       0.00      0.00      0.00        83\n         11       0.00      0.00      0.00        54\n         12       0.00      0.00      0.00        45\n         13       0.00      0.00      0.00        20\n         14       0.00      0.00      0.00        71\n         15       0.00      0.00      0.00        52\n         16       0.00      0.00      0.00        25\n         17       0.00      0.00      0.00         3\n\navg / total       0.16      0.26      0.20      1222\n"}, "SGD-combined_bow": {"fitted_model": null, "train_yhat": null, "test_yhat": null, "train_recall_score": 0.24904798172124903, "test_recall_score": 0.25859247135842883, "train_precision_score": 0.16287738004569688, "test_precision_score": 0.16343044189852698, "train_classification_report": "             precision    recall  f1-score   support\n\n          0       0.00      0.00      0.00        88\n          1       0.00      0.00      0.00        55\n          2       0.00      0.00      0.00        52\n          3       0.65      1.00      0.79       327\n          4       0.00      0.00      0.00        26\n          5       0.00      0.00      0.00        84\n          6       0.00      0.00      0.00       121\n          7       0.00      0.00      0.00        39\n          8       0.00      0.00      0.00        11\n          9       0.00      0.00      0.00       112\n         10       0.00      0.00      0.00        93\n         11       0.00      0.00      0.00        52\n         12       0.00      0.00      0.00        55\n         13       0.00      0.00      0.00        24\n         14       0.00      0.00      0.00        77\n         15       0.00      0.00      0.00        59\n         16       0.00      0.00      0.00        35\n         17       0.00      0.00      0.00         3\n\navg / total       0.16      0.25      0.20      1313\n", "test_classification_report": "             precision    recall  f1-score   support\n\n          0       0.00      0.00      0.00        79\n          1       0.00      0.00      0.00        38\n          2       0.00      0.00      0.00        46\n          3       0.63      1.00      0.77       316\n          4       0.00      0.00      0.00        26\n          5       0.00      0.00      0.00        82\n          6       0.00      0.00      0.00       115\n          7       0.00      0.00      0.00        33\n          8       0.00      0.00      0.00        22\n          9       0.00      0.00      0.00       112\n         10       0.00      0.00      0.00        83\n         11       0.00      0.00      0.00        54\n         12       0.00      0.00      0.00        45\n         13       0.00      0.00      0.00        20\n         14       0.00      0.00      0.00        71\n         15       0.00      0.00      0.00        52\n         16       0.00      0.00      0.00        25\n         17       0.00      0.00      0.00         3\n\navg / total       0.16      0.26      0.20      1222\n"}, "SGD-tmdb_w2v_mean": {"fitted_model": null, "train_yhat": null, "test_yhat": null, "train_recall_score": 0.428027418126428, "test_recall_score": 0.3862520458265139, "train_precision_score": 0.4670430297094392, "test_precision_score": 0.3274086523282838, "train_classification_report": "             precision    recall  f1-score   support\n\n          0       0.00      0.00      0.00        88\n          1       0.00      0.00      0.00        55\n          2       0.77      0.58      0.66        52\n          3       0.66      1.00      0.80       327\n          4       1.00      0.35      0.51        26\n          5       0.74      0.61      0.67        84\n          6       0.00      0.00      0.00       121\n          7       0.00      0.00      0.00        39\n          8       1.00      0.18      0.31        11\n          9       0.89      0.28      0.42       112\n         10       0.21      1.00      0.34        93\n         11       1.00      0.04      0.07        52\n         12       1.00      0.09      0.17        55\n         13       0.00      0.00      0.00        24\n         14       0.00      0.00      0.00        77\n         15       0.00      0.00      0.00        59\n         16       0.92      0.34      0.50        35\n         17       0.00      0.00      0.00         3\n\navg / total       0.47      0.43      0.36      1313\n", "test_classification_report": "             precision    recall  f1-score   support\n\n          0       0.00      0.00      0.00        79\n          1       0.00      0.00      0.00        38\n          2       0.67      0.35      0.46        46\n          3       0.63      1.00      0.78       316\n          4       0.00      0.00      0.00        26\n          5       0.59      0.29      0.39        82\n          6       0.00      0.00      0.00       115\n          7       0.00      0.00      0.00        33\n          8       0.00      0.00      0.00        22\n          9       0.62      0.22      0.33       112\n         10       0.18      1.00      0.30        83\n         11       0.00      0.00      0.00        54\n         12       0.40      0.04      0.08        45\n         13       0.00      0.00      0.00        20\n         14       0.00      0.00      0.00        71\n         15       0.00      0.00      0.00        52\n         16       0.75      0.24      0.36        25\n         17       0.00      0.00      0.00         3\n\navg / total       0.33      0.39      0.30      1222\n"}, "SGD-imdb_w2v_mean": {"fitted_model": null, "train_yhat": null, "test_yhat": null, "train_recall_score": 0.5338918507235338, "test_recall_score": 0.5032733224222586, "train_precision_score": 0.404420356443326, "test_precision_score": 0.32087616917669476, "train_classification_report": "             precision    recall  f1-score   support\n\n          0       0.00      0.00      0.00        88\n          1       0.00      0.00      0.00        55\n          2       0.23      0.98      0.37        52\n          3       0.67      1.00      0.81       327\n          4       0.00      0.00      0.00        26\n          5       0.50      0.75      0.60        84\n          6       0.00      0.00      0.00       121\n          7       0.00      0.00      0.00        39\n          8       0.00      0.00      0.00        11\n          9       0.25      1.00      0.40       112\n         10       0.80      0.77      0.79        93\n         11       1.00      0.04      0.07        52\n         12       0.00      0.00      0.00        55\n         13       1.00      0.38      0.55        24\n         14       0.55      0.73      0.63        77\n         15       0.00      0.00      0.00        59\n         16       1.00      0.26      0.41        35\n         17       0.00      0.00      0.00         3\n\navg / total       0.40      0.53      0.40      1313\n", "test_classification_report": "             precision    recall  f1-score   support\n\n          0       0.00      0.00      0.00        79\n          1       0.00      0.00      0.00        38\n          2       0.21      0.93      0.34        46\n          3       0.64      1.00      0.78       316\n          4       0.00      0.00      0.00        26\n          5       0.50      0.67      0.57        82\n          6       0.00      0.00      0.00       115\n          7       0.00      0.00      0.00        33\n          8       0.00      0.00      0.00        22\n          9       0.24      0.96      0.39       112\n         10       0.61      0.55      0.58        83\n         11       0.00      0.00      0.00        54\n         12       0.00      0.00      0.00        45\n         13       0.40      0.10      0.16        20\n         14       0.41      0.59      0.49        71\n         15       0.00      0.00      0.00        52\n         16       1.00      0.12      0.21        25\n         17       0.00      0.00      0.00         3\n\navg / total       0.32      0.50      0.36      1222\n"}, "SGD-combined_w2v_mean": {"fitted_model": null, "train_yhat": null, "test_yhat": null, "train_recall_score": 0.5064737242955065, "test_recall_score": 0.49018003273322425, "train_precision_score": 0.4471724890392152, "test_precision_score": 0.36466751890114896, "train_classification_report": "             precision    recall  f1-score   support\n\n          0       0.00      0.00      0.00        88\n          1       0.00      0.00      0.00        55\n          2       0.24      1.00      0.38        52\n          3       0.69      0.99      0.81       327\n          4       0.00      0.00      0.00        26\n          5       0.55      0.79      0.65        84\n          6       0.00      0.00      0.00       121\n          7       0.00      0.00      0.00        39\n          8       1.00      0.36      0.53        11\n          9       0.41      0.96      0.58       112\n         10       0.24      1.00      0.39        93\n         11       1.00      0.08      0.14        52\n         12       0.00      0.00      0.00        55\n         13       0.00      0.00      0.00        24\n         14       1.00      0.01      0.03        77\n         15       1.00      0.10      0.18        59\n         16       1.00      0.20      0.33        35\n         17       0.00      0.00      0.00         3\n\navg / total       0.45      0.51      0.37      1313\n", "test_classification_report": "             precision    recall  f1-score   support\n\n          0       0.00      0.00      0.00        79\n          1       0.00      0.00      0.00        38\n          2       0.21      0.98      0.35        46\n          3       0.65      1.00      0.79       316\n          4       0.00      0.00      0.00        26\n          5       0.53      0.72      0.61        82\n          6       0.00      0.00      0.00       115\n          7       0.00      0.00      0.00        33\n          8       0.00      0.00      0.00        22\n          9       0.35      0.81      0.49       112\n         10       0.20      1.00      0.34        83\n         11       1.00      0.04      0.07        54\n         12       0.00      0.00      0.00        45\n         13       0.00      0.00      0.00        20\n         14       0.00      0.00      0.00        71\n         15       1.00      0.02      0.04        52\n         16       1.00      0.12      0.21        25\n         17       0.00      0.00      0.00         3\n\navg / total       0.36      0.49      0.33      1222\n"}, "SVC-tmdb_bow": {"fitted_model": null, "train_yhat": null, "test_yhat": null, "train_recall_score": 0.9337395277989338, "test_recall_score": 0.5130932896890343, "train_precision_score": 0.7606045530917691, "test_precision_score": 0.42103892050045705, "train_classification_report": "             precision    recall  f1-score   support\n\n          0       0.91      1.00      0.95        88\n          1       0.92      1.00      0.96        55\n          2       0.95      1.00      0.97        52\n          3       0.99      0.97      0.98       327\n          4       1.00      1.00      1.00        26\n          5       0.17      1.00      0.29        84\n          6       0.87      1.00      0.93       121\n          7       0.08      1.00      0.14        39\n          8       1.00      1.00      1.00        11\n          9       0.92      1.00      0.96       112\n         10       0.19      1.00      0.31        93\n         11       0.93      1.00      0.96        52\n         12       0.93      1.00      0.96        55\n         13       1.00      1.00      1.00        24\n         14       0.00      0.00      0.00        77\n         15       0.97      1.00      0.98        59\n         16       0.95      1.00      0.97        35\n         17       1.00      1.00      1.00         3\n\navg / total       0.76      0.93      0.80      1313\n", "test_classification_report": "             precision    recall  f1-score   support\n\n          0       0.38      0.32      0.34        79\n          1       0.28      0.21      0.24        38\n          2       0.42      0.22      0.29        46\n          3       0.73      0.75      0.74       316\n          4       0.33      0.04      0.07        26\n          5       0.16      1.00      0.28        82\n          6       0.35      0.41      0.37       115\n          7       0.07      1.00      0.12        33\n          8       0.00      0.00      0.00        22\n          9       0.44      0.41      0.42       112\n         10       0.17      1.00      0.28        83\n         11       0.62      0.30      0.40        54\n         12       0.42      0.29      0.34        45\n         13       0.33      0.05      0.09        20\n         14       0.00      0.00      0.00        71\n         15       0.45      0.25      0.32        52\n         16       0.61      0.44      0.51        25\n         17       0.00      0.00      0.00         3\n\navg / total       0.42      0.51      0.41      1222\n"}, "SVC-imdb_bow": {"fitted_model": null, "train_yhat": null, "test_yhat": null, "train_recall_score": 0.9931454683929931, "test_recall_score": 0.47299509001636664, "train_precision_score": 0.8966054625854732, "test_precision_score": 0.5721672175760132, "train_classification_report": "             precision    recall  f1-score   support\n\n          0       0.97      1.00      0.98        88\n          1       0.98      1.00      0.99        55\n          2       0.98      1.00      0.99        52\n          3       1.00      0.98      0.99       327\n          4       1.00      1.00      1.00        26\n          5       0.99      1.00      0.99        84\n          6       0.94      0.99      0.96       121\n          7       0.08      1.00      0.14        39\n          8       1.00      1.00      1.00        11\n          9       0.96      1.00      0.98       112\n         10       0.98      1.00      0.99        93\n         11       0.96      1.00      0.98        52\n         12       0.11      1.00      0.20        55\n         13       0.05      1.00      0.09        24\n         14       0.96      1.00      0.98        77\n         15       0.98      1.00      0.99        59\n         16       0.97      0.94      0.96        35\n         17       1.00      1.00      1.00         3\n\navg / total       0.90      0.99      0.91      1313\n", "test_classification_report": "             precision    recall  f1-score   support\n\n          0       0.53      0.33      0.41        79\n          1       0.47      0.18      0.26        38\n          2       0.82      0.20      0.32        46\n          3       0.76      0.78      0.77       316\n          4       1.00      0.04      0.07        26\n          5       0.53      0.29      0.38        82\n          6       0.44      0.31      0.37       115\n          7       0.07      1.00      0.12        33\n          8       0.00      0.00      0.00        22\n          9       0.46      0.40      0.43       112\n         10       0.56      0.42      0.48        83\n         11       0.85      0.20      0.33        54\n         12       0.09      1.00      0.17        45\n         13       0.04      1.00      0.08        20\n         14       0.51      0.27      0.35        71\n         15       0.68      0.25      0.37        52\n         16       0.73      0.32      0.44        25\n         17       0.00      0.00      0.00         3\n\navg / total       0.57      0.47      0.45      1222\n"}, "SVC-combined_bow": {"fitted_model": null, "train_yhat": null, "test_yhat": null, "train_recall_score": 0.9383092155369384, "test_recall_score": 0.45662847790507366, "train_precision_score": 0.8774541563268463, "test_precision_score": 0.5809956983282475, "train_classification_report": "             precision    recall  f1-score   support\n\n          0       0.96      1.00      0.98        88\n          1       1.00      1.00      1.00        55\n          2       0.98      1.00      0.99        52\n          3       1.00      0.99      1.00       327\n          4       0.96      1.00      0.98        26\n          5       1.00      1.00      1.00        84\n          6       0.96      1.00      0.98       121\n          7       0.08      1.00      0.14        39\n          8       1.00      1.00      1.00        11\n          9       0.97      1.00      0.98       112\n         10       0.96      1.00      0.98        93\n         11       0.96      1.00      0.98        52\n         12       0.98      1.00      0.99        55\n         13       0.05      1.00      0.09        24\n         14       0.00      0.00      0.00        77\n         15       1.00      1.00      1.00        59\n         16       0.92      0.94      0.93        35\n         17       1.00      1.00      1.00         3\n\navg / total       0.88      0.94      0.89      1313\n", "test_classification_report": "             precision    recall  f1-score   support\n\n          0       0.58      0.32      0.41        79\n          1       0.47      0.18      0.26        38\n          2       0.71      0.22      0.33        46\n          3       0.78      0.85      0.81       316\n          4       0.67      0.08      0.14        26\n          5       0.62      0.26      0.36        82\n          6       0.49      0.34      0.40       115\n          7       0.07      1.00      0.12        33\n          8       0.00      0.00      0.00        22\n          9       0.51      0.38      0.43       112\n         10       0.64      0.49      0.56        83\n         11       0.88      0.26      0.40        54\n         12       0.44      0.18      0.25        45\n         13       0.04      1.00      0.08        20\n         14       0.00      0.00      0.00        71\n         15       0.80      0.23      0.36        52\n         16       0.88      0.56      0.68        25\n         17       0.00      0.00      0.00         3\n\navg / total       0.58      0.46      0.46      1222\n"}, "SVC-tmdb_w2v_mean": {"fitted_model": null, "train_yhat": null, "test_yhat": null, "train_recall_score": 0.8994668697638994, "test_recall_score": 0.5900163666121113, "train_precision_score": 0.8151983091131529, "test_precision_score": 0.5135192245164599, "train_classification_report": "             precision    recall  f1-score   support\n\n          0       0.59      0.92      0.72        88\n          1       0.87      1.00      0.93        55\n          2       0.90      1.00      0.95        52\n          3       0.85      0.84      0.85       327\n          4       1.00      1.00      1.00        26\n          5       0.85      1.00      0.92        84\n          6       0.80      0.97      0.87       121\n          7       0.85      1.00      0.92        39\n          8       0.92      1.00      0.96        11\n          9       0.63      0.62      0.63       112\n         10       0.70      0.71      0.71        93\n         11       0.91      1.00      0.95        52\n         12       0.83      1.00      0.91        55\n         13       1.00      1.00      1.00        24\n         14       0.82      1.00      0.90        77\n         15       0.94      1.00      0.97        59\n         16       0.97      1.00      0.99        35\n         17       1.00      1.00      1.00         3\n\navg / total       0.82      0.90      0.85      1313\n", "test_classification_report": "             precision    recall  f1-score   support\n\n          0       0.44      0.70      0.54        79\n          1       0.20      0.29      0.24        38\n          2       0.41      0.52      0.46        46\n          3       0.78      0.84      0.81       316\n          4       0.23      0.23      0.23        26\n          5       0.35      0.41      0.38        82\n          6       0.39      0.61      0.47       115\n          7       0.28      0.39      0.33        33\n          8       0.67      0.18      0.29        22\n          9       0.51      0.46      0.49       112\n         10       0.62      0.67      0.64        83\n         11       0.41      0.43      0.42        54\n         12       0.30      0.42      0.35        45\n         13       0.26      0.25      0.26        20\n         14       0.36      0.54      0.43        71\n         15       0.54      0.58      0.56        52\n         16       0.55      0.68      0.61        25\n         17       0.00      0.00      0.00         3\n\navg / total       0.51      0.59      0.54      1222\n"}, "SVC-imdb_w2v_mean": {"fitted_model": null, "train_yhat": null, "test_yhat": null, "train_recall_score": 0.9070830159939071, "test_recall_score": 0.6734860883797054, "train_precision_score": 0.7423707197409262, "test_precision_score": 0.5341997691310659, "train_classification_report": "             precision    recall  f1-score   support\n\n          0       0.60      0.67      0.63        88\n          1       0.47      0.65      0.55        55\n          2       0.95      1.00      0.97        52\n          3       0.82      0.92      0.87       327\n          4       0.96      1.00      0.98        26\n          5       0.46      0.74      0.57        84\n          6       0.60      0.92      0.72       121\n          7       0.83      1.00      0.91        39\n          8       0.92      1.00      0.96        11\n          9       0.63      0.93      0.75       112\n         10       0.67      0.92      0.77        93\n         11       0.95      1.00      0.97        52\n         12       0.85      1.00      0.92        55\n         13       1.00      1.00      1.00        24\n         14       0.75      0.99      0.85        77\n         15       0.89      1.00      0.94        59\n         16       1.00      1.00      1.00        35\n         17       0.75      1.00      0.86         3\n\navg / total       0.74      0.91      0.81      1313\n", "test_classification_report": "             precision    recall  f1-score   support\n\n          0       0.56      0.62      0.59        79\n          1       0.26      0.39      0.31        38\n          2       0.53      0.59      0.56        46\n          3       0.75      0.91      0.83       316\n          4       0.26      0.19      0.22        26\n          5       0.47      0.63      0.54        82\n          6       0.42      0.70      0.52       115\n          7       0.38      0.58      0.46        33\n          8       0.73      0.36      0.48        22\n          9       0.44      0.60      0.51       112\n         10       0.46      0.70      0.56        83\n         11       0.59      0.59      0.59        54\n         12       0.30      0.47      0.36        45\n         13       0.24      0.25      0.24        20\n         14       0.37      0.63      0.47        71\n         15       0.59      0.65      0.62        52\n         16       0.81      0.68      0.74        25\n         17       0.00      0.00      0.00         3\n\navg / total       0.53      0.67      0.59      1222\n"}, "SVC-combined_w2v_mean": {"fitted_model": null, "train_yhat": null, "test_yhat": null, "train_recall_score": 0.9146991622239147, "test_recall_score": 0.6841243862520459, "train_precision_score": 0.7628795607669928, "test_precision_score": 0.5339176938803383, "train_classification_report": "             precision    recall  f1-score   support\n\n          0       0.56      0.66      0.61        88\n          1       0.47      0.64      0.54        55\n          2       0.90      1.00      0.95        52\n          3       0.80      0.95      0.87       327\n          4       0.96      1.00      0.98        26\n          5       0.89      1.00      0.94        84\n          6       0.64      0.91      0.75       121\n          7       0.81      1.00      0.90        39\n          8       1.00      1.00      1.00        11\n          9       0.61      0.83      0.70       112\n         10       0.65      0.85      0.73        93\n         11       0.98      1.00      0.99        52\n         12       0.86      1.00      0.92        55\n         13       1.00      1.00      1.00        24\n         14       0.83      0.99      0.90        77\n         15       0.92      1.00      0.96        59\n         16       0.71      1.00      0.83        35\n         17       1.00      1.00      1.00         3\n\navg / total       0.76      0.91      0.83      1313\n", "test_classification_report": "             precision    recall  f1-score   support\n\n          0       0.55      0.66      0.60        79\n          1       0.30      0.47      0.36        38\n          2       0.62      0.63      0.62        46\n          3       0.76      0.94      0.84       316\n          4       0.26      0.19      0.22        26\n          5       0.40      0.45      0.42        82\n          6       0.42      0.71      0.53       115\n          7       0.33      0.61      0.43        33\n          8       0.75      0.41      0.53        22\n          9       0.45      0.61      0.52       112\n         10       0.53      0.76      0.62        83\n         11       0.56      0.61      0.58        54\n         12       0.32      0.42      0.36        45\n         13       0.27      0.30      0.29        20\n         14       0.37      0.58      0.45        71\n         15       0.59      0.71      0.64        52\n         16       0.55      0.84      0.67        25\n         17       0.00      0.00      0.00         3\n\navg / total       0.53      0.68      0.59      1222\n"}}