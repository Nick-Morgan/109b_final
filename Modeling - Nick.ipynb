{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "from ast import literal_eval\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import classification_report, recall_score, precision_score\n",
    "import numpy as np\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we will be trying a number of different models, we decided to create a function that will store all of the outcomes of interest in a dictionary. The function below does an 80/20 train/test split. We also fit all of our models using a 50/50 split, but had better accuracy when using 80/20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, predictors, response, cv=False, params=None):\n",
    "    \"\"\"\n",
    "    evaluate_model()\n",
    "    \n",
    "    -splits the predictors & response variables into train and test sets. \n",
    "    -creates a dictionary of model outcomes that are of interest\n",
    "    -if specified, this function will use cross-validation to determine the optimal parameters for a given model\n",
    "    \n",
    "    inputs:\n",
    "        -model: a model object to be fitted\n",
    "        -predictors: an array, series, or dataframe of predictor variable(s)\n",
    "        -response: an array or series of the response variable\n",
    "        -cv: whether or not to cross-validate the model's parameters (default=False)\n",
    "        -params: if cv=True, params are required to indicate what parameters to optimize in the given model (default=None)\n",
    "        \n",
    "    outputs:\n",
    "        -a results dictionary containing the following:\n",
    "            -a fitted model object\n",
    "    \n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    train_x, test_x = train_test_split(predictors, test_size=0.2, random_state=9001)\n",
    "    train_y, test_y = train_test_split(response, test_size=0.2, random_state=9001)\n",
    "    \n",
    "    if cv:\n",
    "        model = GridSearchCV(model, params, scoring=make_scorer(f1_score, average='micro'))\n",
    "    \n",
    "    classif = OneVsRestClassifier(model)\n",
    "    classif.fit(train_x, train_y)\n",
    "    \n",
    "    train_yhat = classif.predict(train_x)\n",
    "    test_yhat = classif.predict(test_x)\n",
    "    \n",
    "    results['fitted_model'] = classif\n",
    "    \n",
    "    results['train_yhat'] = train_yhat\n",
    "    results['test_yhat'] = test_yhat\n",
    "    \n",
    "    #train_y_score = classif.decision_function(train_x)\n",
    "    #test_y_score = classif.decision_function(test_x)\n",
    "    \n",
    "    #results['train_average_precision'] = average_precision_score(train_y, train_y_score)\n",
    "    #results['test_average_precision'] = average_precision_score(test_y, test_y_score)\n",
    "    \n",
    "    results['train_recall_score'] = recall_score(train_y, train_yhat, average='weighted')\n",
    "    results['test_recall_score'] = recall_score(test_y, test_yhat, average='weighted')\n",
    "    \n",
    "    results['train_precision_score'] = precision_score(train_y, train_yhat,average='weighted')\n",
    "    results['test_precision_score'] = precision_score(test_y, test_yhat,average='weighted')\n",
    "    \n",
    "    results['train_classification_report'] = classification_report(train_y, train_yhat,target_names=target_names)\n",
    "    results['test_classification_report'] = classification_report(test_y, test_yhat,target_names=target_names)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we created the [MultiLabel Binarizer](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MultiLabelBinarizer.html#sklearn.preprocessing.MultiLabelBinarizer) array in a previous notebook, it created 18 classes corresponding to the 18 genres found in our dataset. These classes were labeled as class 0 through class 17, sorted in numeric order of the genre id. In order to improve readability of our report, we will set the target_names to be the name of the genre, rather than the id. The target names need to be in the same order as the MultiLabel Binarizer, so we will do two steps:\n",
    "\n",
    "    1: Sort the keys of the id_to_genre dictionary in ascending numeric order\n",
    "    2: Use the sorted keys against the id_to_genre dictionary to create the ordered target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "id_to_genre = json.load(open('data/id_to_genre.json'))\n",
    "\n",
    "id_to_genre = {int(key):value for key, value in id_to_genre.items()} #convert string keys to int keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Adventure',\n",
       " 'Fantasy',\n",
       " 'Animation',\n",
       " 'Drama',\n",
       " 'Horror',\n",
       " 'Action',\n",
       " 'Comedy',\n",
       " 'History',\n",
       " 'Western',\n",
       " 'Thriller',\n",
       " 'Crime',\n",
       " 'Science Fiction',\n",
       " 'Mystery',\n",
       " 'Music',\n",
       " 'Romance',\n",
       " 'Family',\n",
       " 'War',\n",
       " 'TV Movie']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_names = json.load(open('data/target_names.json'))['tmdb']\n",
    "\n",
    "target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will load in our arrays to be used as predictor variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmdb_bow = np.load('data/tmdb_bow.npy')\n",
    "imdb_bow = np.load('data/imdb_bow.npy')\n",
    "combined_bow = np.load('data/combined_bow.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our Word2Vector and Docs2Vector arrays require 2 additional steps in order to be used as predictors:\n",
    "\n",
    "    1: They need to be converted to an array of lists (they are currently an array of arrays, which is incompatible with the structure of the response variable, which is also an array of lists).\n",
    "    2: The values need to be standardized between 0 and 1, because (todo - there was an error when they were negative. I will have to re-run and see what caused the error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmdb_w2v_mean = np.load('data/tmdb_w2v_mean.npy')\n",
    "imdb_w2v_mean = np.load('data/imdb_w2v_mean.npy')\n",
    "combined_w2v_mean = np.load('data/combined_w2v_mean.npy')\n",
    "\n",
    "tmdb_doc_vec = np.load('data/tmdb_doc_vec.npy')\n",
    "imdb_doc_vec = np.load('data/imdb_doc_vec.npy')\n",
    "combined_doc_vec = np.load('data/combined_doc_vec.npy')\n",
    "\n",
    "tmdb_w2v_mean = np.apply_along_axis(lambda x: list(x), 0, tmdb_w2v_mean)\n",
    "imdb_w2v_mean = np.apply_along_axis(lambda x: list(x), 0, imdb_w2v_mean)\n",
    "combined_w2v_mean = np.apply_along_axis(lambda x: list(x), 0, combined_w2v_mean)\n",
    "\n",
    "tmdb_doc_vec = np.apply_along_axis(lambda x: list(x), 0, tmdb_doc_vec)\n",
    "imdb_doc_vec = np.apply_along_axis(lambda x: list(x), 0, imdb_doc_vec)\n",
    "combined_doc_vec = np.apply_along_axis(lambda x: list(x), 0, combined_doc_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scale = MinMaxScaler()\n",
    "\n",
    "\n",
    "#word2vec scaling\n",
    "scale.fit(tmdb_w2v_mean)\n",
    "tmdb_w2v_mean = scale.transform(tmdb_w2v_mean)\n",
    "\n",
    "scale.fit(imdb_w2v_mean)\n",
    "imdb_w2v_mean = scale.transform(imdb_w2v_mean)\n",
    "\n",
    "scale.fit(combined_w2v_mean)\n",
    "combined_w2v_mean = scale.transform(combined_w2v_mean)\n",
    "\n",
    "#doc2vec scaling\n",
    "scale.fit(tmdb_doc_vec)\n",
    "tmdb_doc_vec = scale.transform(tmdb_doc_vec)\n",
    "\n",
    "scale.fit(imdb_doc_vec)\n",
    "imdb_doc_vec = scale.transform(imdb_doc_vec)\n",
    "\n",
    "scale.fit(combined_doc_vec)\n",
    "combined_doc_vec = scale.transform(combined_doc_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in response variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "binary_tmdb = np.load('data/binary_tmdb.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have all of the parameters necessary to run our function. We will create models using 6 different predictors:\n",
    "\n",
    "    1: Bag of words using the TMDB plot\n",
    "    2: Bag of words using the IMDB plot\n",
    "    3: Bag of words using the combined plots from both sources\n",
    "    4: Word2Vectors using the TMDB plot\n",
    "    5: Word2Vectors using the IMDB plot\n",
    "    6: Word2Vectors using the combined plots from both sources\n",
    "    7: Doc2Vectors using the TMDB plot\n",
    "    8: Doc2Vectors using the IMDB plot\n",
    "    9: Doc2Vectors using the combined plots from both sources\n",
    "    \n",
    "\n",
    "We will use these predictors to create 3 classification models to predict movie genres:\n",
    "\n",
    "    1: Naive-Bayes, with a cross-validated smoothing parameter\n",
    "    2: Stochastic Gradient Descent, with a cross-validated regularization multiplier.\n",
    "    3: Support Vector machines, with a cross-validated penalty parameter of the error term.\n",
    "    \n",
    "    \n",
    "This will result in 27 total models being created. We will store the results of each model in a dictionary, which will allow us to identify the best-performing models.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "modelDict = {'Naive-Bayes':{'model':MultinomialNB(),\n",
    "                           'params':{'alpha':[0.01,0.1,1.0]}},\n",
    "            \n",
    "            'SGD':{'model':SGDClassifier(loss='hinge',penalty='l2',n_iter=5,random_state=9001),\n",
    "                   'params':{'alpha':[0.01,0.1,1.0]}},\n",
    "            \n",
    "            'SVC':{'model':SVC(class_weight='balanced', kernel='linear'),\n",
    "                   'params':{'C':[0.01,0.1,1.0]}}\n",
    "           }\n",
    "\n",
    "predictorDict = {\n",
    "                 'tmdb_bow':tmdb_bow,\n",
    "                 'imdb_bow':imdb_bow,\n",
    "                 'combined_bow':combined_bow,\n",
    "                 'tmdb_w2v_mean':tmdb_w2v_mean,\n",
    "                 'imdb_w2v_mean':imdb_w2v_mean,\n",
    "                 'combined_w2v_mean':combined_w2v_mean,\n",
    "                 'tmdb_doc_vec':tmdb_doc_vec,\n",
    "                 'imdb_doc_vec':imdb_doc_vec,\n",
    "                 'combined_doc_vec':combined_doc_vec\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'combined_doc_vec'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sklearn returns a warning when the function above uses weighted averages on samples that have no predictors. This will not affect our metrics and outputs repetitive information when run in a loop. The warning, that we are choosing to ignore, is as follows:\n",
    "\n",
    "```UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
    "  'precision', 'predicted', average, warn_for)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "resultsDict = {}\n",
    "import warnings\n",
    "with warnings.catch_warnings(): #temporarily ignore the warnings described above\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    for model in modelDict:\n",
    "        for predictor in predictorDict:\n",
    "            resultsDict['{0}-{1}'.format(model,predictor)] = evaluate_model(model = modelDict[model]['model'],\n",
    "                                                                            predictors = predictorDict[predictor], \n",
    "                                                                            response = binary_tmdb,\n",
    "                                                                            cv=True,\n",
    "                                                                            params=modelDict[model]['params'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "This next cell will be removed when we submit our final report. It is just being used now to temporarily store the results of the models to avoid having to re-run the cell above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle #trying to use pickle to see if the model object can be retained while saving, as opposed to json which drops it\n",
    "\n",
    "pickle.dump(resultsDict, open('data/resultsDict.sav','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#start_here\n",
    "\n",
    "import pickle\n",
    "\n",
    "resultsDict = pickle.load(open('data/resultsDict.sav','rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will make a dataframe of the scores for the sake of readability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores = ['train_recall_score','test_recall_score',\n",
    "          'train_precision_score','test_precision_score']\n",
    "\n",
    "results_df = pd.DataFrame(resultsDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results_df = results_df.loc[results_df.index.isin(scores)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_precision_score</th>\n",
       "      <th>test_recall_score</th>\n",
       "      <th>train_precision_score</th>\n",
       "      <th>train_recall_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Naive-Bayes-combined_bow</th>\n",
       "      <td>0.725255</td>\n",
       "      <td>0.377953</td>\n",
       "      <td>0.982521</td>\n",
       "      <td>0.926914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Naive-Bayes-combined_doc_vec</th>\n",
       "      <td>0.166339</td>\n",
       "      <td>0.255906</td>\n",
       "      <td>0.163924</td>\n",
       "      <td>0.254321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Naive-Bayes-combined_w2v_mean</th>\n",
       "      <td>0.456782</td>\n",
       "      <td>0.267717</td>\n",
       "      <td>0.583491</td>\n",
       "      <td>0.274074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Naive-Bayes-imdb_bow</th>\n",
       "      <td>0.596821</td>\n",
       "      <td>0.340551</td>\n",
       "      <td>0.948176</td>\n",
       "      <td>0.780741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Naive-Bayes-imdb_doc_vec</th>\n",
       "      <td>0.166339</td>\n",
       "      <td>0.255906</td>\n",
       "      <td>0.163924</td>\n",
       "      <td>0.254321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Naive-Bayes-imdb_w2v_mean</th>\n",
       "      <td>0.178442</td>\n",
       "      <td>0.253937</td>\n",
       "      <td>0.605336</td>\n",
       "      <td>0.262716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Naive-Bayes-tmdb_bow</th>\n",
       "      <td>0.619958</td>\n",
       "      <td>0.301181</td>\n",
       "      <td>0.970122</td>\n",
       "      <td>0.79358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Naive-Bayes-tmdb_doc_vec</th>\n",
       "      <td>0.166339</td>\n",
       "      <td>0.255906</td>\n",
       "      <td>0.163924</td>\n",
       "      <td>0.254321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Naive-Bayes-tmdb_w2v_mean</th>\n",
       "      <td>0.316826</td>\n",
       "      <td>0.261811</td>\n",
       "      <td>0.494266</td>\n",
       "      <td>0.265185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGD-combined_bow</th>\n",
       "      <td>0.166339</td>\n",
       "      <td>0.255906</td>\n",
       "      <td>0.163924</td>\n",
       "      <td>0.254321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGD-combined_doc_vec</th>\n",
       "      <td>0.166339</td>\n",
       "      <td>0.255906</td>\n",
       "      <td>0.163924</td>\n",
       "      <td>0.254321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGD-combined_w2v_mean</th>\n",
       "      <td>0.514741</td>\n",
       "      <td>0.409449</td>\n",
       "      <td>0.602544</td>\n",
       "      <td>0.42963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGD-imdb_bow</th>\n",
       "      <td>0.166339</td>\n",
       "      <td>0.255906</td>\n",
       "      <td>0.163924</td>\n",
       "      <td>0.254321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGD-imdb_doc_vec</th>\n",
       "      <td>0.166339</td>\n",
       "      <td>0.255906</td>\n",
       "      <td>0.163924</td>\n",
       "      <td>0.254321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGD-imdb_w2v_mean</th>\n",
       "      <td>0.380598</td>\n",
       "      <td>0.444882</td>\n",
       "      <td>0.539381</td>\n",
       "      <td>0.497284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGD-tmdb_bow</th>\n",
       "      <td>0.166339</td>\n",
       "      <td>0.255906</td>\n",
       "      <td>0.163924</td>\n",
       "      <td>0.254321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGD-tmdb_doc_vec</th>\n",
       "      <td>0.166339</td>\n",
       "      <td>0.255906</td>\n",
       "      <td>0.163924</td>\n",
       "      <td>0.254321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGD-tmdb_w2v_mean</th>\n",
       "      <td>0.470563</td>\n",
       "      <td>0.379921</td>\n",
       "      <td>0.619262</td>\n",
       "      <td>0.430617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC-combined_bow</th>\n",
       "      <td>0.678057</td>\n",
       "      <td>0.525591</td>\n",
       "      <td>0.95214</td>\n",
       "      <td>0.985679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC-combined_doc_vec</th>\n",
       "      <td>0.186744</td>\n",
       "      <td>0.525591</td>\n",
       "      <td>0.194323</td>\n",
       "      <td>0.532346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC-combined_w2v_mean</th>\n",
       "      <td>0.558305</td>\n",
       "      <td>0.688976</td>\n",
       "      <td>0.742788</td>\n",
       "      <td>0.893827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC-imdb_bow</th>\n",
       "      <td>0.607838</td>\n",
       "      <td>0.551181</td>\n",
       "      <td>0.87196</td>\n",
       "      <td>0.974321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC-imdb_doc_vec</th>\n",
       "      <td>0.153214</td>\n",
       "      <td>0.340551</td>\n",
       "      <td>0.162445</td>\n",
       "      <td>0.37679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC-imdb_w2v_mean</th>\n",
       "      <td>0.537334</td>\n",
       "      <td>0.685039</td>\n",
       "      <td>0.681017</td>\n",
       "      <td>0.864691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC-tmdb_bow</th>\n",
       "      <td>0.475574</td>\n",
       "      <td>0.496063</td>\n",
       "      <td>0.815313</td>\n",
       "      <td>0.946667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC-tmdb_doc_vec</th>\n",
       "      <td>0.186744</td>\n",
       "      <td>0.525591</td>\n",
       "      <td>0.194323</td>\n",
       "      <td>0.532346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC-tmdb_w2v_mean</th>\n",
       "      <td>0.540201</td>\n",
       "      <td>0.633858</td>\n",
       "      <td>0.748116</td>\n",
       "      <td>0.877531</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              test_precision_score test_recall_score  \\\n",
       "Naive-Bayes-combined_bow                  0.725255          0.377953   \n",
       "Naive-Bayes-combined_doc_vec              0.166339          0.255906   \n",
       "Naive-Bayes-combined_w2v_mean             0.456782          0.267717   \n",
       "Naive-Bayes-imdb_bow                      0.596821          0.340551   \n",
       "Naive-Bayes-imdb_doc_vec                  0.166339          0.255906   \n",
       "Naive-Bayes-imdb_w2v_mean                 0.178442          0.253937   \n",
       "Naive-Bayes-tmdb_bow                      0.619958          0.301181   \n",
       "Naive-Bayes-tmdb_doc_vec                  0.166339          0.255906   \n",
       "Naive-Bayes-tmdb_w2v_mean                 0.316826          0.261811   \n",
       "SGD-combined_bow                          0.166339          0.255906   \n",
       "SGD-combined_doc_vec                      0.166339          0.255906   \n",
       "SGD-combined_w2v_mean                     0.514741          0.409449   \n",
       "SGD-imdb_bow                              0.166339          0.255906   \n",
       "SGD-imdb_doc_vec                          0.166339          0.255906   \n",
       "SGD-imdb_w2v_mean                         0.380598          0.444882   \n",
       "SGD-tmdb_bow                              0.166339          0.255906   \n",
       "SGD-tmdb_doc_vec                          0.166339          0.255906   \n",
       "SGD-tmdb_w2v_mean                         0.470563          0.379921   \n",
       "SVC-combined_bow                          0.678057          0.525591   \n",
       "SVC-combined_doc_vec                      0.186744          0.525591   \n",
       "SVC-combined_w2v_mean                     0.558305          0.688976   \n",
       "SVC-imdb_bow                              0.607838          0.551181   \n",
       "SVC-imdb_doc_vec                          0.153214          0.340551   \n",
       "SVC-imdb_w2v_mean                         0.537334          0.685039   \n",
       "SVC-tmdb_bow                              0.475574          0.496063   \n",
       "SVC-tmdb_doc_vec                          0.186744          0.525591   \n",
       "SVC-tmdb_w2v_mean                         0.540201          0.633858   \n",
       "\n",
       "                              train_precision_score train_recall_score  \n",
       "Naive-Bayes-combined_bow                   0.982521           0.926914  \n",
       "Naive-Bayes-combined_doc_vec               0.163924           0.254321  \n",
       "Naive-Bayes-combined_w2v_mean              0.583491           0.274074  \n",
       "Naive-Bayes-imdb_bow                       0.948176           0.780741  \n",
       "Naive-Bayes-imdb_doc_vec                   0.163924           0.254321  \n",
       "Naive-Bayes-imdb_w2v_mean                  0.605336           0.262716  \n",
       "Naive-Bayes-tmdb_bow                       0.970122            0.79358  \n",
       "Naive-Bayes-tmdb_doc_vec                   0.163924           0.254321  \n",
       "Naive-Bayes-tmdb_w2v_mean                  0.494266           0.265185  \n",
       "SGD-combined_bow                           0.163924           0.254321  \n",
       "SGD-combined_doc_vec                       0.163924           0.254321  \n",
       "SGD-combined_w2v_mean                      0.602544            0.42963  \n",
       "SGD-imdb_bow                               0.163924           0.254321  \n",
       "SGD-imdb_doc_vec                           0.163924           0.254321  \n",
       "SGD-imdb_w2v_mean                          0.539381           0.497284  \n",
       "SGD-tmdb_bow                               0.163924           0.254321  \n",
       "SGD-tmdb_doc_vec                           0.163924           0.254321  \n",
       "SGD-tmdb_w2v_mean                          0.619262           0.430617  \n",
       "SVC-combined_bow                            0.95214           0.985679  \n",
       "SVC-combined_doc_vec                       0.194323           0.532346  \n",
       "SVC-combined_w2v_mean                      0.742788           0.893827  \n",
       "SVC-imdb_bow                                0.87196           0.974321  \n",
       "SVC-imdb_doc_vec                           0.162445            0.37679  \n",
       "SVC-imdb_w2v_mean                          0.681017           0.864691  \n",
       "SVC-tmdb_bow                               0.815313           0.946667  \n",
       "SVC-tmdb_doc_vec                           0.194323           0.532346  \n",
       "SVC-tmdb_w2v_mean                          0.748116           0.877531  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = results_df.transpose()\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few of our models have identical scores for all outcomes, as demonstrated by the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_precision_score</th>\n",
       "      <th>test_recall_score</th>\n",
       "      <th>train_precision_score</th>\n",
       "      <th>train_recall_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Naive-Bayes-combined_doc_vec</th>\n",
       "      <td>0.166339</td>\n",
       "      <td>0.255906</td>\n",
       "      <td>0.163924</td>\n",
       "      <td>0.254321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Naive-Bayes-imdb_doc_vec</th>\n",
       "      <td>0.166339</td>\n",
       "      <td>0.255906</td>\n",
       "      <td>0.163924</td>\n",
       "      <td>0.254321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Naive-Bayes-tmdb_doc_vec</th>\n",
       "      <td>0.166339</td>\n",
       "      <td>0.255906</td>\n",
       "      <td>0.163924</td>\n",
       "      <td>0.254321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGD-combined_bow</th>\n",
       "      <td>0.166339</td>\n",
       "      <td>0.255906</td>\n",
       "      <td>0.163924</td>\n",
       "      <td>0.254321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGD-combined_doc_vec</th>\n",
       "      <td>0.166339</td>\n",
       "      <td>0.255906</td>\n",
       "      <td>0.163924</td>\n",
       "      <td>0.254321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGD-imdb_bow</th>\n",
       "      <td>0.166339</td>\n",
       "      <td>0.255906</td>\n",
       "      <td>0.163924</td>\n",
       "      <td>0.254321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGD-imdb_doc_vec</th>\n",
       "      <td>0.166339</td>\n",
       "      <td>0.255906</td>\n",
       "      <td>0.163924</td>\n",
       "      <td>0.254321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGD-tmdb_bow</th>\n",
       "      <td>0.166339</td>\n",
       "      <td>0.255906</td>\n",
       "      <td>0.163924</td>\n",
       "      <td>0.254321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGD-tmdb_doc_vec</th>\n",
       "      <td>0.166339</td>\n",
       "      <td>0.255906</td>\n",
       "      <td>0.163924</td>\n",
       "      <td>0.254321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC-combined_doc_vec</th>\n",
       "      <td>0.186744</td>\n",
       "      <td>0.525591</td>\n",
       "      <td>0.194323</td>\n",
       "      <td>0.532346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC-tmdb_doc_vec</th>\n",
       "      <td>0.186744</td>\n",
       "      <td>0.525591</td>\n",
       "      <td>0.194323</td>\n",
       "      <td>0.532346</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             test_precision_score test_recall_score  \\\n",
       "Naive-Bayes-combined_doc_vec             0.166339          0.255906   \n",
       "Naive-Bayes-imdb_doc_vec                 0.166339          0.255906   \n",
       "Naive-Bayes-tmdb_doc_vec                 0.166339          0.255906   \n",
       "SGD-combined_bow                         0.166339          0.255906   \n",
       "SGD-combined_doc_vec                     0.166339          0.255906   \n",
       "SGD-imdb_bow                             0.166339          0.255906   \n",
       "SGD-imdb_doc_vec                         0.166339          0.255906   \n",
       "SGD-tmdb_bow                             0.166339          0.255906   \n",
       "SGD-tmdb_doc_vec                         0.166339          0.255906   \n",
       "SVC-combined_doc_vec                     0.186744          0.525591   \n",
       "SVC-tmdb_doc_vec                         0.186744          0.525591   \n",
       "\n",
       "                             train_precision_score train_recall_score  \n",
       "Naive-Bayes-combined_doc_vec              0.163924           0.254321  \n",
       "Naive-Bayes-imdb_doc_vec                  0.163924           0.254321  \n",
       "Naive-Bayes-tmdb_doc_vec                  0.163924           0.254321  \n",
       "SGD-combined_bow                          0.163924           0.254321  \n",
       "SGD-combined_doc_vec                      0.163924           0.254321  \n",
       "SGD-imdb_bow                              0.163924           0.254321  \n",
       "SGD-imdb_doc_vec                          0.163924           0.254321  \n",
       "SGD-tmdb_bow                              0.163924           0.254321  \n",
       "SGD-tmdb_doc_vec                          0.163924           0.254321  \n",
       "SVC-combined_doc_vec                      0.194323           0.532346  \n",
       "SVC-tmdb_doc_vec                          0.194323           0.532346  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicate_scores = pd.concat(group for _, group in results_df.groupby((scores)) if len(group) > 1)\n",
    "duplicate_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 2 duplicate values occuring. One occurs in 9 models, and the other occurs with 2. We will explain these one at a time, beginning with the group of 9 models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_1 = list(duplicate_scores.index.values[:9])\n",
    "group_2 = list(duplicate_scores.index.values[9:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classification report shows the issue occuring in group 1. Instead of printing out 2 reports for each of the 9 models, we will instead write code that proves that all 9 models have identical classification reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in range(len(group_1)):\n",
    "    if resultsDict[group_1[0]]['train_classification_report'] != resultsDict[group_1[model]]['train_classification_report']:\n",
    "        print('Train classification reports do not match between model 0 and model {}'.format(model))\n",
    "    \n",
    "    if resultsDict[group_1[0]]['test_classification_report'] != resultsDict[group_1[model]]['test_classification_report']:\n",
    "        print('Test classification reports do not match between model 0 and model {}'.format(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have proven that all 9 models have identical classification reports, we can print a single set of reports to observe what is happening across all groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "      Adventure       0.00      0.00      0.00       137\n",
      "        Fantasy       0.00      0.00      0.00        76\n",
      "      Animation       0.00      0.00      0.00        82\n",
      "          Drama       0.64      1.00      0.78       515\n",
      "         Horror       0.00      0.00      0.00        41\n",
      "         Action       0.00      0.00      0.00       124\n",
      "         Comedy       0.00      0.00      0.00       189\n",
      "        History       0.00      0.00      0.00        54\n",
      "        Western       0.00      0.00      0.00        25\n",
      "       Thriller       0.00      0.00      0.00       184\n",
      "          Crime       0.00      0.00      0.00       143\n",
      "Science Fiction       0.00      0.00      0.00        81\n",
      "        Mystery       0.00      0.00      0.00        77\n",
      "          Music       0.00      0.00      0.00        34\n",
      "        Romance       0.00      0.00      0.00       124\n",
      "         Family       0.00      0.00      0.00        92\n",
      "            War       0.00      0.00      0.00        42\n",
      "       TV Movie       0.00      0.00      0.00         5\n",
      "\n",
      "    avg / total       0.16      0.25      0.20      2025\n",
      "\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "      Adventure       0.00      0.00      0.00        31\n",
      "        Fantasy       0.00      0.00      0.00        17\n",
      "      Animation       0.00      0.00      0.00        17\n",
      "          Drama       0.65      1.00      0.79       130\n",
      "         Horror       0.00      0.00      0.00        11\n",
      "         Action       0.00      0.00      0.00        40\n",
      "         Comedy       0.00      0.00      0.00        49\n",
      "        History       0.00      0.00      0.00        19\n",
      "        Western       0.00      0.00      0.00         8\n",
      "       Thriller       0.00      0.00      0.00        39\n",
      "          Crime       0.00      0.00      0.00        33\n",
      "Science Fiction       0.00      0.00      0.00        25\n",
      "        Mystery       0.00      0.00      0.00        19\n",
      "          Music       0.00      0.00      0.00         5\n",
      "        Romance       0.00      0.00      0.00        28\n",
      "         Family       0.00      0.00      0.00        17\n",
      "            War       0.00      0.00      0.00        19\n",
      "       TV Movie       0.00      0.00      0.00         1\n",
      "\n",
      "    avg / total       0.17      0.26      0.20       508\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(resultsDict[group_1[0]]['train_classification_report'])\n",
    "print(resultsDict[group_1[0]]['test_classification_report'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of these 9 models are being overfit - for both the train and test dataset, each of these models is predicting that 100% of the movies will be genres. This is because of the large number of drama movies in the dataset (this is demonstrated in our EDA notebook). Fine-tuning the penalization parameters may help with these models being overfit, but that exploration is outside the scope of this analysis. We will instead focus on the models that are not being overfit, after first exploring the other group of duplicates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, let's make sure the classification reports are identical between the two models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "if resultsDict[group_2[0]]['train_classification_report'] != resultsDict[group_2[1]]['train_classification_report']:\n",
    "    print('Train classification reports do not match between model 0 and model 1')\n",
    "    \n",
    "if resultsDict[group_2[0]]['test_classification_report'] != resultsDict[group_2[1]]['test_classification_report']:\n",
    "    print('Test classification reports do not match between model 0 and model 1')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two reports are identical, so let's take a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "      Adventure       0.29      0.72      0.41       137\n",
      "        Fantasy       0.10      1.00      0.17        76\n",
      "      Animation       0.10      1.00      0.19        82\n",
      "          Drama       0.00      0.00      0.00       515\n",
      "         Horror       0.05      1.00      0.10        41\n",
      "         Action       0.32      0.73      0.44       124\n",
      "         Comedy       0.53      0.16      0.24       189\n",
      "        History       0.14      0.69      0.23        54\n",
      "        Western       0.11      0.76      0.19        25\n",
      "       Thriller       0.23      1.00      0.37       184\n",
      "          Crime       0.18      1.00      0.30       143\n",
      "Science Fiction       0.28      0.64      0.39        81\n",
      "        Mystery       0.16      0.77      0.27        77\n",
      "          Music       0.09      0.76      0.16        34\n",
      "        Romance       0.45      0.36      0.40       124\n",
      "         Family       0.24      0.59      0.34        92\n",
      "            War       0.07      0.98      0.13        42\n",
      "       TV Movie       0.00      0.00      0.00         5\n",
      "\n",
      "    avg / total       0.19      0.53      0.23      2025\n",
      "\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "      Adventure       0.26      0.74      0.38        31\n",
      "        Fantasy       0.09      1.00      0.16        17\n",
      "      Animation       0.09      1.00      0.16        17\n",
      "          Drama       0.00      0.00      0.00       130\n",
      "         Horror       0.06      1.00      0.10        11\n",
      "         Action       0.36      0.68      0.47        40\n",
      "         Comedy       0.50      0.14      0.22        49\n",
      "        History       0.17      0.58      0.27        19\n",
      "        Western       0.14      0.75      0.24         8\n",
      "       Thriller       0.20      1.00      0.33        39\n",
      "          Crime       0.17      1.00      0.28        33\n",
      "Science Fiction       0.32      0.72      0.44        25\n",
      "        Mystery       0.15      0.68      0.24        19\n",
      "          Music       0.04      0.60      0.08         5\n",
      "        Romance       0.38      0.39      0.39        28\n",
      "         Family       0.16      0.71      0.26        17\n",
      "            War       0.13      1.00      0.23        19\n",
      "       TV Movie       0.00      0.00      0.00         1\n",
      "\n",
      "    avg / total       0.19      0.53      0.22       508\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(resultsDict[group_2[0]]['train_classification_report'])\n",
    "\n",
    "print(resultsDict[group_2[0]]['test_classification_report'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SVC-combined_doc_vec', 'SVC-tmdb_doc_vec']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_recall = results_df['test_recall_score'].idxmax()\n",
    "best_precision = results_df['test_precision_score'].idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_precision_score</th>\n",
       "      <th>test_recall_score</th>\n",
       "      <th>train_precision_score</th>\n",
       "      <th>train_recall_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Naive-Bayes-combined_bow</th>\n",
       "      <td>0.725255</td>\n",
       "      <td>0.377953</td>\n",
       "      <td>0.982521</td>\n",
       "      <td>0.926914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC-combined_w2v_mean</th>\n",
       "      <td>0.558305</td>\n",
       "      <td>0.688976</td>\n",
       "      <td>0.742788</td>\n",
       "      <td>0.893827</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         test_precision_score test_recall_score  \\\n",
       "Naive-Bayes-combined_bow             0.725255          0.377953   \n",
       "SVC-combined_w2v_mean                0.558305          0.688976   \n",
       "\n",
       "                         train_precision_score train_recall_score  \n",
       "Naive-Bayes-combined_bow              0.982521           0.926914  \n",
       "SVC-combined_w2v_mean                 0.742788           0.893827  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.loc[results_df.index.isin([best_recall, best_precision])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "todo: update analysis here. support vector machines no longer has the best accuracy\n",
    "\n",
    "We see that Support Vector Machines result in the best accuracy - both in terms of precision and recall. Combining the plots from both data sources also results in the best accuracy, which intuitively makes sense as combining the sources results in a more descriptive plot.\n",
    "\n",
    "Bag-of-words results in the best `test_precision_score`, although the model appears to be overfitting. Perhaps increasing the penalty parameter of the error term would result in better test scores, although our existing results are sufficient enough to move forward without exploring that option.\n",
    "\n",
    "WordsVectors results in the best `test_recall_score`, although the test_precision_score is less accurate than the results from the bag-of-words model.\n",
    "\n",
    "Next we will look at the full results of each model by using the classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results:  Naive-Bayes-combined_bow\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "      Adventure       0.97      0.88      0.92       137\n",
      "        Fantasy       1.00      0.72      0.84        76\n",
      "      Animation       1.00      1.00      1.00        82\n",
      "          Drama       0.96      0.99      0.98       515\n",
      "         Horror       1.00      1.00      1.00        41\n",
      "         Action       0.98      0.88      0.93       124\n",
      "         Comedy       1.00      0.94      0.97       189\n",
      "        History       1.00      1.00      1.00        54\n",
      "        Western       1.00      1.00      1.00        25\n",
      "       Thriller       0.98      0.85      0.91       184\n",
      "          Crime       1.00      0.90      0.95       143\n",
      "Science Fiction       0.99      0.93      0.96        81\n",
      "        Mystery       0.99      0.99      0.99        77\n",
      "          Music       1.00      0.82      0.90        34\n",
      "        Romance       1.00      0.85      0.92       124\n",
      "         Family       1.00      0.90      0.95        92\n",
      "            War       1.00      1.00      1.00        42\n",
      "       TV Movie       1.00      1.00      1.00         5\n",
      "\n",
      "    avg / total       0.98      0.93      0.95      2025\n",
      "\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "      Adventure       0.78      0.45      0.57        31\n",
      "        Fantasy       1.00      0.18      0.30        17\n",
      "      Animation       1.00      0.06      0.11        17\n",
      "          Drama       0.80      0.88      0.84       130\n",
      "         Horror       1.00      0.09      0.17        11\n",
      "         Action       0.86      0.30      0.44        40\n",
      "         Comedy       0.88      0.14      0.25        49\n",
      "        History       0.00      0.00      0.00        19\n",
      "        Western       0.00      0.00      0.00         8\n",
      "       Thriller       0.69      0.28      0.40        39\n",
      "          Crime       0.82      0.27      0.41        33\n",
      "Science Fiction       0.80      0.32      0.46        25\n",
      "        Mystery       0.00      0.00      0.00        19\n",
      "          Music       0.00      0.00      0.00         5\n",
      "        Romance       0.40      0.07      0.12        28\n",
      "         Family       0.80      0.24      0.36        17\n",
      "            War       1.00      0.26      0.42        19\n",
      "       TV Movie       0.00      0.00      0.00         1\n",
      "\n",
      "    avg / total       0.73      0.38      0.44       508\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Results: ', best_precision)\n",
    "print(resultsDict[best_precision]['train_classification_report'])\n",
    "print(resultsDict[best_precision]['test_classification_report'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results:  SVC-combined_w2v_mean\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "      Adventure       0.58      0.73      0.65       137\n",
      "        Fantasy       0.38      0.68      0.49        76\n",
      "      Animation       0.89      1.00      0.94        82\n",
      "          Drama       0.90      0.86      0.88       515\n",
      "         Horror       0.93      1.00      0.96        41\n",
      "         Action       0.56      0.92      0.70       124\n",
      "         Comedy       0.59      0.91      0.71       189\n",
      "        History       0.90      1.00      0.95        54\n",
      "        Western       0.78      1.00      0.88        25\n",
      "       Thriller       0.61      0.86      0.71       184\n",
      "          Crime       0.62      0.81      0.70       143\n",
      "Science Fiction       0.89      1.00      0.94        81\n",
      "        Mystery       0.73      1.00      0.85        77\n",
      "          Music       0.92      1.00      0.96        34\n",
      "        Romance       0.70      0.98      0.82       124\n",
      "         Family       0.88      1.00      0.94        92\n",
      "            War       0.95      1.00      0.98        42\n",
      "       TV Movie       1.00      1.00      1.00         5\n",
      "\n",
      "    avg / total       0.74      0.89      0.80      2025\n",
      "\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "      Adventure       0.43      0.74      0.55        31\n",
      "        Fantasy       0.27      0.65      0.38        17\n",
      "      Animation       0.52      0.76      0.62        17\n",
      "          Drama       0.85      0.77      0.81       130\n",
      "         Horror       0.60      0.55      0.57        11\n",
      "         Action       0.46      0.68      0.55        40\n",
      "         Comedy       0.49      0.76      0.60        49\n",
      "        History       0.20      0.16      0.18        19\n",
      "        Western       0.80      1.00      0.89         8\n",
      "       Thriller       0.42      0.77      0.55        39\n",
      "          Crime       0.56      0.73      0.63        33\n",
      "Science Fiction       0.61      0.68      0.64        25\n",
      "        Mystery       0.28      0.37      0.32        19\n",
      "          Music       0.17      0.40      0.24         5\n",
      "        Romance       0.29      0.46      0.36        28\n",
      "         Family       0.52      0.76      0.62        17\n",
      "            War       0.70      0.84      0.76        19\n",
      "       TV Movie       0.00      0.00      0.00         1\n",
      "\n",
      "    avg / total       0.56      0.69      0.61       508\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Results: ', best_recall)\n",
    "print(resultsDict[best_recall]['train_classification_report'])\n",
    "print(resultsDict[best_recall]['test_classification_report'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "todo: add analysis for the classification reports, listed above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_precision_score</th>\n",
       "      <th>test_recall_score</th>\n",
       "      <th>train_precision_score</th>\n",
       "      <th>train_recall_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Naive-Bayes-combined_doc_vec</th>\n",
       "      <td>0.166339</td>\n",
       "      <td>0.255906</td>\n",
       "      <td>0.163924</td>\n",
       "      <td>0.254321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Naive-Bayes-imdb_doc_vec</th>\n",
       "      <td>0.166339</td>\n",
       "      <td>0.255906</td>\n",
       "      <td>0.163924</td>\n",
       "      <td>0.254321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Naive-Bayes-tmdb_doc_vec</th>\n",
       "      <td>0.166339</td>\n",
       "      <td>0.255906</td>\n",
       "      <td>0.163924</td>\n",
       "      <td>0.254321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGD-combined_doc_vec</th>\n",
       "      <td>0.166339</td>\n",
       "      <td>0.255906</td>\n",
       "      <td>0.163924</td>\n",
       "      <td>0.254321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGD-imdb_doc_vec</th>\n",
       "      <td>0.166339</td>\n",
       "      <td>0.255906</td>\n",
       "      <td>0.163924</td>\n",
       "      <td>0.254321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGD-tmdb_doc_vec</th>\n",
       "      <td>0.166339</td>\n",
       "      <td>0.255906</td>\n",
       "      <td>0.163924</td>\n",
       "      <td>0.254321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC-combined_doc_vec</th>\n",
       "      <td>0.186744</td>\n",
       "      <td>0.525591</td>\n",
       "      <td>0.194323</td>\n",
       "      <td>0.532346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC-imdb_doc_vec</th>\n",
       "      <td>0.153214</td>\n",
       "      <td>0.340551</td>\n",
       "      <td>0.162445</td>\n",
       "      <td>0.37679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC-tmdb_doc_vec</th>\n",
       "      <td>0.186744</td>\n",
       "      <td>0.525591</td>\n",
       "      <td>0.194323</td>\n",
       "      <td>0.532346</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             test_precision_score test_recall_score  \\\n",
       "Naive-Bayes-combined_doc_vec             0.166339          0.255906   \n",
       "Naive-Bayes-imdb_doc_vec                 0.166339          0.255906   \n",
       "Naive-Bayes-tmdb_doc_vec                 0.166339          0.255906   \n",
       "SGD-combined_doc_vec                     0.166339          0.255906   \n",
       "SGD-imdb_doc_vec                         0.166339          0.255906   \n",
       "SGD-tmdb_doc_vec                         0.166339          0.255906   \n",
       "SVC-combined_doc_vec                     0.186744          0.525591   \n",
       "SVC-imdb_doc_vec                         0.153214          0.340551   \n",
       "SVC-tmdb_doc_vec                         0.186744          0.525591   \n",
       "\n",
       "                             train_precision_score train_recall_score  \n",
       "Naive-Bayes-combined_doc_vec              0.163924           0.254321  \n",
       "Naive-Bayes-imdb_doc_vec                  0.163924           0.254321  \n",
       "Naive-Bayes-tmdb_doc_vec                  0.163924           0.254321  \n",
       "SGD-combined_doc_vec                      0.163924           0.254321  \n",
       "SGD-imdb_doc_vec                          0.163924           0.254321  \n",
       "SGD-tmdb_doc_vec                          0.163924           0.254321  \n",
       "SVC-combined_doc_vec                      0.194323           0.532346  \n",
       "SVC-imdb_doc_vec                          0.162445            0.37679  \n",
       "SVC-tmdb_doc_vec                          0.194323           0.532346  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.filter(like='doc_vec', axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of the doc_vec models have very poor predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subsetting\n",
    "\n",
    "Subsetting on the data source:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_source_results = {}\n",
    "\n",
    "for group in ['imdb', 'tmdb', 'combined']:\n",
    "    subset = results_df.filter(like=group, axis=0)\n",
    "\n",
    "    \n",
    "    data_source_results[group] = {'min_test_precision': subset['test_precision_score'].min(),\n",
    "                                'max_test_precision': subset['test_precision_score'].max(),\n",
    "                                'mean_test_precision':subset['test_precision_score'].mean(),\n",
    "                                'min_test_recall': subset['test_recall_score'].min(),\n",
    "                                'max_test_recall': subset['test_recall_score'].max(),\n",
    "                                'mean_test_recall':subset['test_recall_score'].mean()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min_test_precision</th>\n",
       "      <th>max_test_precision</th>\n",
       "      <th>mean_test_precision</th>\n",
       "      <th>min_test_recall</th>\n",
       "      <th>max_test_recall</th>\n",
       "      <th>mean_test_recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>combined</th>\n",
       "      <td>0.166339</td>\n",
       "      <td>0.725255</td>\n",
       "      <td>0.402100</td>\n",
       "      <td>0.255906</td>\n",
       "      <td>0.688976</td>\n",
       "      <td>0.395888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>imdb</th>\n",
       "      <td>0.153214</td>\n",
       "      <td>0.607838</td>\n",
       "      <td>0.328140</td>\n",
       "      <td>0.253937</td>\n",
       "      <td>0.685039</td>\n",
       "      <td>0.375984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tmdb</th>\n",
       "      <td>0.166339</td>\n",
       "      <td>0.619958</td>\n",
       "      <td>0.345431</td>\n",
       "      <td>0.255906</td>\n",
       "      <td>0.633858</td>\n",
       "      <td>0.374016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          min_test_precision  max_test_precision  mean_test_precision  \\\n",
       "combined            0.166339            0.725255             0.402100   \n",
       "imdb                0.153214            0.607838             0.328140   \n",
       "tmdb                0.166339            0.619958             0.345431   \n",
       "\n",
       "          min_test_recall  max_test_recall  mean_test_recall  \n",
       "combined         0.255906         0.688976          0.395888  \n",
       "imdb             0.253937         0.685039          0.375984  \n",
       "tmdb             0.255906         0.633858          0.374016  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_order = ['min_test_precision','max_test_precision','mean_test_precision',\n",
    "                                            'min_test_recall','max_test_recall','mean_test_recall']\n",
    "\n",
    "pd.DataFrame(data_source_results).transpose()[column_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_results = {}\n",
    "for group in ['bow', 'w2v', 'doc_vec']:\n",
    "    subset = results_df.filter(like=group, axis=0)\n",
    "\n",
    "    predictor_results[group] = {'min_test_precision': subset['test_precision_score'].min(),\n",
    "                                'max_test_precision': subset['test_precision_score'].max(),\n",
    "                                'mean_test_precision':subset['test_precision_score'].mean(),\n",
    "                                'min_test_recall': subset['test_recall_score'].min(),\n",
    "                                'max_test_recall': subset['test_recall_score'].max(),\n",
    "                                'mean_test_recall':subset['test_recall_score'].mean()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min_test_precision</th>\n",
       "      <th>max_test_precision</th>\n",
       "      <th>mean_test_precision</th>\n",
       "      <th>min_test_recall</th>\n",
       "      <th>max_test_recall</th>\n",
       "      <th>mean_test_recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bow</th>\n",
       "      <td>0.166339</td>\n",
       "      <td>0.725255</td>\n",
       "      <td>0.466946</td>\n",
       "      <td>0.255906</td>\n",
       "      <td>0.551181</td>\n",
       "      <td>0.373360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doc_vec</th>\n",
       "      <td>0.153214</td>\n",
       "      <td>0.186744</td>\n",
       "      <td>0.169415</td>\n",
       "      <td>0.255906</td>\n",
       "      <td>0.525591</td>\n",
       "      <td>0.325241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w2v</th>\n",
       "      <td>0.178442</td>\n",
       "      <td>0.558305</td>\n",
       "      <td>0.439310</td>\n",
       "      <td>0.253937</td>\n",
       "      <td>0.688976</td>\n",
       "      <td>0.447288</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         min_test_precision  max_test_precision  mean_test_precision  \\\n",
       "bow                0.166339            0.725255             0.466946   \n",
       "doc_vec            0.153214            0.186744             0.169415   \n",
       "w2v                0.178442            0.558305             0.439310   \n",
       "\n",
       "         min_test_recall  max_test_recall  mean_test_recall  \n",
       "bow             0.255906         0.551181          0.373360  \n",
       "doc_vec         0.255906         0.525591          0.325241  \n",
       "w2v             0.253937         0.688976          0.447288  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(predictor_results).transpose()[column_order]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
