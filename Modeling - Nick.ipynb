{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "from ast import literal_eval\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far this dataframe isn't being used. But I am keeping it here for reference until a final decision is made on storing the numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of columns in our 'movies.csv' that need to be read in using literal_eval\n",
    "#to ensure they are represented as vectors rather than strings\n",
    "converterList = ['imdb_genres', 'tmdb_genres', 'binary_tmdb', 'binary_imdb',\n",
    "                 'imdb_clean', 'tmdb_clean',\n",
    "               'imdb_w2v_plot', 'tmdb_w2v_plot', 'tmdb_bow_plot', 'imdb_bow_plot']\n",
    "\n",
    "converterDict = {column: literal_eval for column in converterList}\n",
    "\n",
    "movies = pd.read_csv('data/movies.csv', encoding='utf-8',\n",
    "                     converters=converterDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load in previously saved ndarrays\n",
    "binary_tmdb = np.load('data/binary_tmdb.npy')\n",
    "binary_imdb = np.load('data/binary_imdb.npy')\n",
    "\n",
    "tmdb_bow = np.load('data/tmdb_bow.npy')\n",
    "imdb_bow = np.load('data/tmdb_bow.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y, test_y = train_test_split(binary_tmdb, test_size=0.5, random_state=9001)\n",
    "train_x, test_x = train_test_split(tmdb_bow, test_size=0.5, random_state=9001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight='balanced', coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),...refit=True, return_train_score=True,\n",
       "       scoring=make_scorer(f1_score, average=micro), verbose=0),\n",
       "          n_jobs=1)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {'kernel':['linear'], 'C':[0.01, 0.1, 1.0]}\n",
    "gridCV = GridSearchCV(SVC(class_weight='balanced'), parameters, scoring=make_scorer(f1_score, average='micro'))\n",
    "classif = OneVsRestClassifier(gridCV)\n",
    "\n",
    "classif.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      1.00      0.95        88\n",
      "          1       0.92      1.00      0.96        55\n",
      "          2       0.95      1.00      0.97        52\n",
      "          3       0.99      0.97      0.98       327\n",
      "          4       1.00      1.00      1.00        26\n",
      "          5       0.17      1.00      0.29        84\n",
      "          6       0.87      1.00      0.93       121\n",
      "          7       0.08      1.00      0.14        39\n",
      "          8       1.00      1.00      1.00        11\n",
      "          9       0.92      1.00      0.96       112\n",
      "         10       0.19      1.00      0.31        93\n",
      "         11       0.93      1.00      0.96        52\n",
      "         12       0.93      1.00      0.96        55\n",
      "         13       1.00      1.00      1.00        24\n",
      "         14       0.00      0.00      0.00        77\n",
      "         15       0.97      1.00      0.98        59\n",
      "         16       0.95      1.00      0.97        35\n",
      "         17       1.00      1.00      1.00         3\n",
      "\n",
      "avg / total       0.76      0.93      0.80      1313\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.38      0.32      0.34        79\n",
      "          1       0.28      0.21      0.24        38\n",
      "          2       0.42      0.22      0.29        46\n",
      "          3       0.73      0.75      0.74       316\n",
      "          4       0.33      0.04      0.07        26\n",
      "          5       0.16      1.00      0.28        82\n",
      "          6       0.35      0.41      0.37       115\n",
      "          7       0.07      1.00      0.12        33\n",
      "          8       0.00      0.00      0.00        22\n",
      "          9       0.44      0.41      0.42       112\n",
      "         10       0.17      1.00      0.28        83\n",
      "         11       0.62      0.30      0.40        54\n",
      "         12       0.42      0.29      0.34        45\n",
      "         13       0.33      0.05      0.09        20\n",
      "         14       0.00      0.00      0.00        71\n",
      "         15       0.45      0.25      0.32        52\n",
      "         16       0.61      0.44      0.51        25\n",
      "         17       0.00      0.00      0.00         3\n",
      "\n",
      "avg / total       0.42      0.51      0.41      1222\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\A706GZZ\\Documents\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "train_yhat=classif.predict(train_x)\n",
    "test_yhat=classif.predict(test_x)\n",
    "\n",
    "#todo - I can add the target_names parameter but i don't know the order \n",
    "#       that the genres are listed\n",
    "\n",
    "print (classification_report(train_y, train_yhat))\n",
    "print('\\n\\n')\n",
    "print (classification_report(test_y, test_yhat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that overfitting may be occuring. The training precision/recall is 0.76/0.93, respectively, whereas the test results are 0.42/0.51, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
