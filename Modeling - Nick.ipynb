{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "from ast import literal_eval\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far this dataframe isn't being used. But I am keeping it here for reference until a final decision is made on storing the numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#list of columns in our 'movies.csv' that need to be read in using literal_eval\n",
    "#to ensure they are represented as vectors rather than strings\n",
    "converterList = ['imdb_genres', 'tmdb_genres', 'binary_tmdb', 'binary_imdb',\n",
    "                 'imdb_clean', 'tmdb_clean',\n",
    "               'imdb_w2v_plot', 'tmdb_w2v_plot', 'tmdb_bow_plot', 'imdb_bow_plot']\n",
    "\n",
    "converterDict = {column: literal_eval for column in converterList}\n",
    "\n",
    "movies = pd.read_csv('data/movies.csv', encoding='utf-8',\n",
    "                     converters=converterDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load in previously saved ndarrays\n",
    "binary_tmdb = np.load('data/binary_tmdb.npy') #response\n",
    "binary_imdb = np.load('data/binary_imdb.npy') #response\n",
    "\n",
    "tmdb_bow = np.load('data/tmdb_bow.npy') #predictor\n",
    "imdb_bow = np.load('data/tmdb_bow.npy') #predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_y, test_y = train_test_split(binary_tmdb, test_size=0.5, random_state=9001)\n",
    "train_bow, test_bow = train_test_split(tmdb_bow, test_size=0.5, random_state=9001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight='balanced', coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),...refit=True, return_train_score=True,\n",
       "       scoring=make_scorer(f1_score, average=micro), verbose=0),\n",
       "          n_jobs=1)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {'kernel':['linear'], 'C':[0.01, 0.1, 1.0]}\n",
    "gridCV = GridSearchCV(SVC(class_weight='balanced'), parameters, scoring=make_scorer(f1_score, average='micro'))\n",
    "classif = OneVsRestClassifier(gridCV)\n",
    "\n",
    "classif.fit(train_bow, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      1.00      0.95        88\n",
      "          1       0.92      1.00      0.96        55\n",
      "          2       0.95      1.00      0.97        52\n",
      "          3       0.99      0.97      0.98       327\n",
      "          4       1.00      1.00      1.00        26\n",
      "          5       0.17      1.00      0.29        84\n",
      "          6       0.87      1.00      0.93       121\n",
      "          7       0.08      1.00      0.14        39\n",
      "          8       1.00      1.00      1.00        11\n",
      "          9       0.92      1.00      0.96       112\n",
      "         10       0.19      1.00      0.31        93\n",
      "         11       0.93      1.00      0.96        52\n",
      "         12       0.93      1.00      0.96        55\n",
      "         13       1.00      1.00      1.00        24\n",
      "         14       0.00      0.00      0.00        77\n",
      "         15       0.97      1.00      0.98        59\n",
      "         16       0.95      1.00      0.97        35\n",
      "         17       1.00      1.00      1.00         3\n",
      "\n",
      "avg / total       0.76      0.93      0.80      1313\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.38      0.32      0.34        79\n",
      "          1       0.28      0.21      0.24        38\n",
      "          2       0.42      0.22      0.29        46\n",
      "          3       0.73      0.75      0.74       316\n",
      "          4       0.33      0.04      0.07        26\n",
      "          5       0.16      1.00      0.28        82\n",
      "          6       0.35      0.41      0.37       115\n",
      "          7       0.07      1.00      0.12        33\n",
      "          8       0.00      0.00      0.00        22\n",
      "          9       0.44      0.41      0.42       112\n",
      "         10       0.17      1.00      0.28        83\n",
      "         11       0.62      0.30      0.40        54\n",
      "         12       0.42      0.29      0.34        45\n",
      "         13       0.33      0.05      0.09        20\n",
      "         14       0.00      0.00      0.00        71\n",
      "         15       0.45      0.25      0.32        52\n",
      "         16       0.61      0.44      0.51        25\n",
      "         17       0.00      0.00      0.00         3\n",
      "\n",
      "avg / total       0.42      0.51      0.41      1222\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\A706GZZ\\Documents\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "train_yhat_bow=classif.predict(train_bow)\n",
    "test_yhat_bow=classif.predict(test_bow)\n",
    "\n",
    "#todo - I can add the target_names parameter but i don't know the order \n",
    "#       that the genres are listed\n",
    "\n",
    "print (classification_report(train_y, train_yhat_bow))\n",
    "print('\\n\\n')\n",
    "print (classification_report(test_y, test_yhat_bow))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that overfitting may be occuring. The training precision/recall is 0.76/0.93, respectively, whereas the test results are 0.42/0.51, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Words2Vec\n",
    "\n",
    "One additional step is required before we can use w2v as a predictor variable. The binarizer variable is an array of lists, whereas w2v is an array of arrays. To maintain consistency, we will have to turn w2v into an array of lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmdb_w2v = np.load('data/tmdb_w2v.npy')\n",
    "imdb_w2v = np.load('data/imdb_w2v.npy')\n",
    "\n",
    "tmdb_w2v = np.apply_along_axis(lambda x: list(x), 0, tmdb_w2v)\n",
    "imdb_w2v = np.apply_along_axis(lambda x: list(x), 0, tmdb_w2v)\n",
    "\n",
    "train_w2v, test_w2v = train_test_split(tmdb_w2v, test_size=0.5, random_state=9001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight='balanced', coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),...refit=True, return_train_score=True,\n",
       "       scoring=make_scorer(f1_score, average=micro), verbose=0),\n",
       "          n_jobs=1)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {'kernel':['linear'], 'C':[0.01, 0.1, 1.0]}\n",
    "gridCV = GridSearchCV(SVC(class_weight='balanced'), parameters, scoring=make_scorer(f1_score, average='micro'))\n",
    "classif = OneVsRestClassifier(gridCV)\n",
    "\n",
    "classif.fit(train_w2v, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.59      0.92      0.72        88\n",
      "          1       0.11      1.00      0.20        55\n",
      "          2       0.59      0.92      0.72        52\n",
      "          3       0.90      0.84      0.87       327\n",
      "          4       0.52      0.88      0.66        26\n",
      "          5       0.17      1.00      0.29        84\n",
      "          6       0.56      0.95      0.70       121\n",
      "          7       0.08      1.00      0.14        39\n",
      "          8       0.92      1.00      0.96        11\n",
      "          9       0.62      0.62      0.62       112\n",
      "         10       0.67      0.71      0.69        93\n",
      "         11       0.62      0.96      0.76        52\n",
      "         12       0.11      1.00      0.20        55\n",
      "         13       0.05      1.00      0.09        24\n",
      "         14       0.00      0.00      0.00        77\n",
      "         15       0.63      0.97      0.77        59\n",
      "         16       0.66      1.00      0.80        35\n",
      "         17       1.00      1.00      1.00         3\n",
      "\n",
      "avg / total       0.55      0.83      0.61      1313\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.44      0.68      0.54        79\n",
      "          1       0.08      1.00      0.14        38\n",
      "          2       0.47      0.72      0.57        46\n",
      "          3       0.78      0.77      0.78       316\n",
      "          4       0.27      0.46      0.34        26\n",
      "          5       0.16      1.00      0.28        82\n",
      "          6       0.40      0.73      0.52       115\n",
      "          7       0.07      1.00      0.12        33\n",
      "          8       0.67      0.27      0.39        22\n",
      "          9       0.50      0.46      0.48       112\n",
      "         10       0.60      0.70      0.65        83\n",
      "         11       0.45      0.61      0.52        54\n",
      "         12       0.09      1.00      0.17        45\n",
      "         13       0.04      1.00      0.08        20\n",
      "         14       0.00      0.00      0.00        71\n",
      "         15       0.53      0.77      0.63        52\n",
      "         16       0.50      0.88      0.64        25\n",
      "         17       0.00      0.00      0.00         3\n",
      "\n",
      "avg / total       0.46      0.70      0.50      1222\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\A706GZZ\\Documents\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "train_yhat_w2v = classif.predict(train_w2v)\n",
    "test_yhat_w2v = classif.predict(test_w2v)\n",
    "\n",
    "#todo - I can add the target_names parameter but i don't know the order \n",
    "#       that the genres are listed\n",
    "\n",
    "print (classification_report(train_y, train_yhat_w2v))\n",
    "print('\\n\\n')\n",
    "print (classification_report(test_y, test_yhat_w2v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pipeline(model, predictors, response, cv=False, params=None):\n",
    "    results = {}\n",
    "    train_x, test_x = train_test_split(predictors, test_size=0.5, random_state=9001)\n",
    "    train_y, test_y = train_test_split(response, test_size=0.5, random_state=9001)\n",
    "    \n",
    "    if cv:\n",
    "        model = GridSearchCV(model, params, scoring=make_scorer(f1_score, average='micro'))\n",
    "    \n",
    "    classif = OneVsRestClassifier(model)\n",
    "    classif.fit(train_x, train_y)\n",
    "    \n",
    "    results['train_yhat'] = classif.predict(train_x)\n",
    "    results['test_yhat'] = classif.predict(test_x)\n",
    "    \n",
    "    train_y_score = classif.decision_function(train_x)\n",
    "    test_y_score = classif.decision_function(test_x)\n",
    "    \n",
    "    results['train_average_precision'] = \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
